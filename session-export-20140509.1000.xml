<schedule created="2014-05-11T13:49:37.666266"><day date="2014-07-21"><entry id="83"><category>Talk</category><audience>Novice</audience><topics><topic>Other</topic></topics><start>0900</start><duration>60</duration><room id="3">B07/B08</room><title>Conversing with people living in poverty</title><description>43% of the world's population live on less than &#8364;1.5 per day.&#13;
&#13;
The United Nations defines poverty as a "lack of basic capacity to&#13;
participate effectively in society".  While we often think of the poor&#13;
as lacking primarily food and shelter, the UN definition highlights&#13;
their isolation. They have the least access to society's knowledge and&#13;
services and the most difficulty making themselves and their needs&#13;
heard in our democracies.&#13;
&#13;
While smart phones and an exploding ability to collect and process&#13;
information are transforming our access to knowledge and the way we&#13;
organize and participate in our societies, those living in poverty&#13;
have largely been left out. This has to change.&#13;
&#13;
Basic mobile phones present an opportunity to effect this change&#13;
[3]. Only three countries in the world have fewer than 65 mobile&#13;
phones per 100 people [4]. The majority of these phones are not&#13;
Android or iPhones, but they do nevertheless provide a means of&#13;
communication -- via voice calls, SMSes [6], USSD [7] and instant&#13;
messaging.&#13;
&#13;
By comparison, 25 countries have less than 5% internet penetration&#13;
[5].&#13;
&#13;
Vumi [1] is an open source text messaging system designed to reach out&#13;
to those in poverty on a massive scale via their mobile phones. It's&#13;
written in Python using Twisted.&#13;
&#13;
Vumi is already used to:&#13;
&#13;
  * provide Wikipedia access over USSD and SMS in Kenya [8].&#13;
  * register a million voters in Libya [10].&#13;
  * deliver health information to mothers in South Africa [9].&#13;
  * prevent election violence in Kenya [11].&#13;
&#13;
This talk will cover:&#13;
&#13;
  * a brief overview of mobile networking and cellphone use in Africa&#13;
  * why we built Vumi&#13;
  * the challenges of operating in unreliable environments&#13;
  * an overview of Vumi's features and architecture&#13;
  * how you can help!&#13;
&#13;
Vumi features some cutting edge design choices:&#13;
&#13;
  * horizontally scalable Twisted processes communicating using RabbitMQ.&#13;
  * declarative data models backed by Riak.&#13;
  * sharing common data models between Django and Twisted.&#13;
  * sandboxing hosted Javascript code from Python.&#13;
&#13;
Overview of challenges Vumi addresses:&#13;
&#13;
*Scalability*: Vumi needs to support both small scale applications (demos, pilot projects, applications tailored for a particular community) and large ones (things that everyone within a country might use). We address this using Twisted workers that exchange messages via RabbitMQ and store data in Riak. Having projects share RabbitMQ and Riak instances significantly reduces the overhead for small projects (e.g. its not cost effective to launch the recommended minimum of 5 Riak servers for a small project).&#13;
&#13;
*Barriers to entry*: Often the people with good ideas don't have access to one of many things needed to run a production system themselves, e.g. capital, time, stable infrastructure. We address this by providing a hosted Vumi instance that runs sandboxed Javascript applications. All the application author needs is their idea, the ability to write Javascript and upload it to our servers. The target audience here is African entrepreneurs at incubator spaces like iHub (Nairobi), kLab (Kigali), BongoHive (Lusaka) and JoziHub (Johannesburg).&#13;
&#13;
*Unreliable third-party systems*: It's one thing for parts of ones own system to go down, it's another for crucial third-party systems to go down. Vumi takes an SMTP-like approach to solving this and uses persistent queues so that messages can back up in the queue while third-party systems are down and be processed when they become available again. We also feedback information on whether third-party messaging systems have accepted or reject messages to the application that initiated them.&#13;
&#13;
Vumi is developed by the Praekelt Foundation [2] (and individual contributors!).&#13;
&#13;
  [1]: &lt;http://vumi.org/&gt; "Vumi"&#13;
  [2]: &lt;http://praekeltfoundation.org/&gt; "Praekelt Foundation"&#13;
  [3]: &lt;http://www.youtube.com/watch?v=0bXjgx4J0C4#t=20&gt; "Spotlight on Africa"&#13;
  [4]: &lt;http://en.wikipedia.org/wiki/List_of_countries_by_number_of_mobile_phones_in_use&gt;&#13;
  [5]: &lt;http://en.wikipedia.org/wiki/List_of_countries_by_number_of_Internet_users&gt;&#13;
  [6]: &lt;http://en.wikipedia.org/wiki/Short_Message_Service&gt;&#13;
  [7]: &lt;http://en.wikipedia.org/wiki/Unstructured_Supplementary_Service_Data&#13;
  [8]: &lt;http://blog.praekeltfoundation.org/post/65981723628/wikipedia-zero-over-text-with-praekelt-foundation&gt;&#13;
  [9]: &lt;http://blog.praekeltfoundation.org/post/65042080515/mama-launches-healthy-family-nutrition-programme&gt;&#13;
  [10]: &lt;http://www.libyaherald.com/2014/01/01/over-one-million-register-for-constitutional-elections-on-final-sms-registration-day/#axzz2sroHcg00&gt;&#13;
  [11]: &lt;http://blog.praekeltfoundation.org/post/51210616848/the-texting-will-never-be-done-peace-messages-in-kenya&gt;</description><speakers><speaker id="754"><name>Simon Cross</name><profile>https://ep2014.europython.eu//en/accounts/profile/754/</profile><image>https://ep2014.europython.eu//site_media/avatars/simon.cross.png</image></speaker></speakers></entry><entry id="81"><category>Talk</category><audience>Advanced</audience><topics><topic>Best Practices</topic></topics><start>0900</start><duration>60</duration><room id="1">C01</room><title>Automatic code reviews</title><description>Overview&#13;
----&#13;
&#13;
Static analysis tools are a great idea in theory, but are not often really used in practice. These tools usually require quite a lot of initial effort to get set up in a way which produces meaningful output for you or your organisation's particular coding style and values. As a result, it's common to see initial enthusiasm replaced by ignoring the tools.&#13;
&#13;
I believe that such tools can be incredibly beneficial however, and even go so far as to provide an automatic code review, and with this talk I want to show people how to get the best out of the tools, as well as address the shortcomings and explain what you can and cannot expect. &#13;
&#13;
This talk is aimed at experienced developers who are interested in improving their coding practices but who have either never tried static analysis tools, or who have not seen the upsides. It will hopefully also be useful to people who do use the tools, perhaps introducing them to new tools or concepts they were not aware of yet.&#13;
&#13;
At the end of the talk, I hope people leave with a good idea of what advantages introducing these tools into their coding practices would bring, and know where to start in order to fit the tools into their practices in a way which will match their coding style.&#13;
&#13;
Outline &#13;
---&#13;
&#13;
* Intro&#13;
    * Who am I, and what do I know that enables me to do this talk?&#13;
&#13;
* What makes a good code review?&#13;
    * Preventing technical debt and ensuring future maintainability&#13;
    * Catching incorrect assumptions&#13;
    * Finding stale or unused code&#13;
&#13;
* The parts of a code review, and what tools exist to automate this, and what kind of things the tools are useful for&#13;
    * Catching out-and-out errors&#13;
        * `pylint`, `pyflakes`&#13;
        * Incorrect arguments to functions, incorrect types etc&#13;
        * Difficulties specific to Python, and how this can be mitigated or improved&#13;
    * Code smells - warning about possible problems&#13;
        * `pylint`, `pyflakes`&#13;
        * Code smells (what are they?)&#13;
        * The job of tools is to highlight possible errors, not be 100% correct. It's better to overwarn than to underwarn.&#13;
    * Style conventions&#13;
        * Having a coding style reduces the 'ramp-up' time for developers new to a piece of code&#13;
        * PEP8 and `pep8.py`&#13;
    * Suggestions for code to refector&#13;
        * Complexity - what is it, and what does it tell us?&#13;
        * `mccabe` tool&#13;
    * Code duplication&#13;
        * possibly talk about `pysimilar`, although this may not be mature enough by EuroPython&#13;
&#13;
* Problems of the above tools, and what to do about it&#13;
    * On existing codebases, they can produce hundreds or thousands of errors, many of which are not interesting or useful&#13;
        * Lots of false positives especially due to the dynamic nature of Python&#13;
        * There are some quick wins - some default warnings are a bit overly strict&#13;
        * use `pylint` plugins, or create your own&#13;
        * (possible addition about `python-skeletons`, which is currently a proposal)&#13;
    * Differing configuration styles, argument styles, output formats...&#13;
    * They require a lot of tweaking in order to fit your coding style&#13;
    * Generally configuration is too specific to particular companies or organisations, and there's not much value to get from using someone else's configuration&#13;
    * Is it worth it then? Absolutely! A day of setting up the tools will save you more than a day some time in the future, either by keeping your codebase easy to maintain, or by telling you of a problem you hadn't noticed.&#13;
&#13;
* `prospector`, and how it aims to help&#13;
    * Default (opinionated!) settings to hide as much noise as possible and focus on very bad errors&#13;
    * Unified output format&#13;
    * Composable configuration, to aid sharing of the "hard work"&#13;
&#13;
* Summary&#13;
    * It's hard at first but worth it! (what isn't?)</description><speakers><speaker id="402"><name>carlio</name><profile>https://ep2014.europython.eu//en/accounts/profile/402/</profile><image></image></speaker></speakers></entry><entry id="62"><category>Talk</category><audience>Advanced</audience><topics><topic>Web</topic></topics><start>0900</start><duration>60</duration><room id="2">B05/B06</room><title>How Disqus is using Django as the basis of our Service Oriented Architecture</title><description># The talk!&#13;
## ~10 min: Introduce what a SOA is&#13;
- What is a Service Oriented Arcitecture (SOA)?&#13;
    - Separation of concerns makes deployments faster and smaller.&#13;
    - Doing one thing well is better than doing two things kinda ok.&#13;
    - Development speed&#13;
        - SOA enables us to ship code FAST&#13;
        - Code commit to production is &lt; 2 minutes&#13;
&#13;
    - What are the basic kinds of services?&#13;
        - RPC: function calls over the network&#13;
        - REST: Basic/bulk data access over the network&#13;
        - Evented/Queue: Respond to data broadcasts in realtime&#13;
        - Why I personally think (Evented + REST) &gt; RPC.&#13;
- Why is Disqus moving towards a SOA? (Hint, it is for #webscale)&#13;
&#13;
## ~10 min: breaking up an existing application&#13;
- How Disqus is migrating from a monolithic django app to many smaller django apps.&#13;
    - We wanted to leverage our existing know-how of django&#13;
        - This includes all of our tooling&#13;
        - Products like sentry (https://github.com/getsentry/sentry)&#13;
        - And other monitoring/deployment infrastructure&#13;
    - We didn't plan well for growing, so there are a lot of lessons here)&#13;
    - How will authorization be done in services that can't access the user table?&#13;
&#13;
- How are we still leveraging Django in our services that are not wsgi apps&#13;
    - When we use management commands? (A lot)&#13;
    - When to use celery tasks? (Less than we anticipated)&#13;
&#13;
## ~20 min: Case study of the Disqus Ad Server&#13;
- migrate the functionality to a new service&#13;
    - Broke the Ad Server out from the monolithic app&#13;
    - Broke out the data portion into another service&#13;
    - Code structure of how we use multiple services&#13;
        - wsgi entry points&#13;
        - management commands&#13;
&#13;
- what went wrong&#13;
    - original code was not a well formed stand alone django app&#13;
    - still can't remove old code due to poor separation of concerns&#13;
&#13;
- what went right&#13;
    - average ship time of a feature went from days to hours&#13;
    - leveraged Django so new employees have a super fast learning curve&#13;
&#13;
# bonus material if there is time&#13;
(could possibly a 5-10 minute lightning talk too)&#13;
&#13;
## how we do experimentation to make more $&#8364;&#163;!&#13;
- A/B testing in the Disqus Ad Server&#13;
    - we use switches, but gargoyle wasn't working well&#13;
        - https://github.com/disqus/gargoyle&#13;
    - enter gutter!&#13;
        - https://github.com/disqus/gutter&#13;
    - switches in Django (or flask, or anything!)&#13;
    - zookeeper or redis backed&#13;
    - super fast&#13;
    - how we report decisions to the client, and how we track that data</description><speakers><speaker id="26"><name>adam</name><profile>https://ep2014.europython.eu//en/accounts/profile/26/</profile><image></image></speaker></speakers></entry><entry id="42"><category>Talk</category><audience>Novice</audience><topics><topic>Other</topic></topics><start>0900</start><duration>60</duration><room id="5">A08</room><title>Documenting your project with MkDocs.</title><description>This talk will be a practical introduction to MkDocs, a new tool for creating documentation from Markdown:&#13;
&#13;
* The background behind MkDocs and the motivation for creating a new documentation tool.&#13;
* Comparing against Sphinx - what benefits each tool provides.&#13;
* Getting starting with MkDocs - how to write, theme and publish your documentation.&#13;
* Under the covers - how MkDocs works, and some asides on a couple of the neat Python libraries that it uses.&#13;
&#13;
</description><speakers><speaker id="189"><name>Tom Christie</name><profile>https://ep2014.europython.eu//en/accounts/profile/189/</profile><image>https://ep2014.europython.eu//site_media/avatars/Photo_29-10-2013_11_46_31.jpg</image></speaker></speakers></entry><entry id="12"><category>Talk</category><audience>Novice</audience><topics><topic>Best Practices</topic></topics><start>0900</start><duration>60</duration><room id="4">B09</room><title>Lessons learned from building Elasticsearch client</title><description>Last year we decided to create official clients for the most popular languages, Python included.&#13;
&#13;
Some of the goals were:&#13;
&#13;
* support the complete API of elasticsearch including all parameters&#13;
* provide a 1-to-1 mapping to the rest API to avoid having opinions and provide a familiar interface to our users consistent across languages and evironments&#13;
* degrade gracefully when the es cluster is changing (nodes dropping out or being added)&#13;
* flexibility - allow users to customize and extend the clients easily to suit their, potentially unique, environment&#13;
&#13;
In this talk I would like to take you through the process of designing said client, the challenges we faced and the solutions we picked. Amongst other things I will touch on the difference between languages (and their respective communities), the architecture of the client itself, mapping out the API and making sure it stays up to date and integrating with existing tools.&#13;
</description><speakers><speaker id="152"><name>Honza Kr&#225;l</name><profile>https://ep2014.europython.eu//en/accounts/profile/152/</profile><image>https://ep2014.europython.eu//site_media/avatars/cb.jpg</image></speaker></speakers></entry><entry id="38"><category>Talk</category><audience>Novice</audience><topics><topic>System Administration</topic></topics><start>1000</start><duration>30</duration><room id="5">A08</room><title>Supercharge your development environment using Docker</title><description>Rough Guidelines:&#13;
&#13;
1. Describe what is LXC  (Linux containers)&#13;
2. Benefits of using containers instead of traditional VM's&#13;
2. Explain where Docker comes in&#13;
3. Show how to build simple containers using Dockefile syntax&#13;
4. What are container images and how to share them&#13;
5. How to share private container images&#13;
6. Tips and tricks on how to automate </description><speakers><speaker id="429"><name>Deni Bertovic</name><profile>https://ep2014.europython.eu//en/accounts/profile/429/</profile><image>https://ep2014.europython.eu//site_media/avatars/me_2.jpg</image></speaker></speakers></entry><entry id="31"><category>Talk</category><audience>Advanced</audience><topics><topic>Other</topic></topics><start>1000</start><duration>30</duration><room id="2">B05/B06</room><title>Jigna: a seamless Python-JS bridge to create rich HTML UIs for Python apps</title><description>[Jigna][7] is an HTML based solution to create rich user interfaces for standalone Python applications. The HTML view for your Python model is rendered via Qt's [QtWebkit][3] browser widget where Jigna creates automatic two-way data binding between the underlying Python model and the view so that the view is always in sync with the model and can interact with it.&#13;
&#13;
Let us say we have a nice model written in Python (specifically, in [Traits][1]):&#13;
&#13;
    from traits.api import HasTraits, Str, on_trait_change&#13;
    &#13;
    class Model(HasTraits):&#13;
        name = Str&#13;
        greeting = Str&#13;
    &#13;
        @on_trait_change('name')&#13;
        def update_greeting(self):&#13;
            self.greeting = "Hello " + self.name&#13;
&#13;
        def clear(self):&#13;
            self.name = ""&#13;
    &#13;
    model = Model(name='Fred')&#13;
&#13;
We would like to write simple HTML to visualize this and have the model and view &#13;
be fully connected. Here is a sample HTML (an [AngularJS][2] template):&#13;
&#13;
    body_html = """&#13;
        Name: &lt;input ng-model="model.name"&gt; &lt;br&gt;&#13;
        Greeting:&#13;
        &lt;h1&gt;{{model.greeting}}&lt;/h1&gt; &lt;br&gt;&#13;
&#13;
        &lt;button ng-click="model.clear()"&gt;Clear&lt;/button&gt;&#13;
    """&#13;
&#13;
Notice how the HTML is directly referencing Python model attributes via `model.name` &#13;
and `model.greeting`, and calling its method via `model.clear()`. We bind this declarative view to the model and create a Qt based UI:&#13;
&#13;
    from jigna.api import View&#13;
    view = View(body_html=body_html)&#13;
    &#13;
    from PySide import QtGui&#13;
    app = QtGui.QApplication([])&#13;
    view.show(model=model)&#13;
    app.exec_()&#13;
&#13;
This produces an HTML UI which responds automatically to any changes in the &#13;
model and vice-versa. It can optionally be styled with CSS and made interactive &#13;
with Javascript. Clearly the above example is a toy example, but this shows a &#13;
nice way of easily building rich, live user interfaces for Python apps. &#13;
&#13;
This is nice for several reasons:&#13;
&#13;
* The view code is declarative and hence easy to read.&#13;
* The binding between the model and the view is automatic.&#13;
* HTML/CSS/JS today is very powerful &#13;
    * there are many JS libraries for a variety of tasks.&#13;
    * it is much easier to find people who know HTML/CSS/JS than Qt or a native &#13;
    toolkit.&#13;
    * your development team doesn't have to worry about creating widgets or the &#13;
    limitations in the toolkit's widget set as there are thousands of developers &#13;
    worldwide creating awesome CSS/JS widgets for you.&#13;
* There is a complete separation of view from the model and this allows us to &#13;
hand off the entire UI to an HTML/CSS/JS guru.&#13;
&#13;
And if this were not enough, the view can also be easily served on a regular web browser &#13;
if we just did the following:&#13;
&#13;
    view.serve(model=model)&#13;
&#13;
This starts up a web server to which one can connect multiple browsers to see &#13;
and interact with the model.&#13;
&#13;
You can check out the source code for Jigna [here][7].&#13;
&#13;
### How is this different from existing options?&#13;
&#13;
For a simple Python desktop application, it is relatively easy to create an HTML &#13;
view using a webkit browser widget.  However, the connection between the model &#13;
and the HTML UI can be tricky resulting in fairly complicated code.  Most web &#13;
frameworks provide this functionality but are web-centric, and are centered &#13;
around building web applications, not desktop applications. One of the implications of this is that the template is usually static and does not respond to changes on the server side immediately.&#13;
&#13;
Our goal is to be able to build a desktop UI completely in HTML where the HTML &#13;
template always remains live by referring directly to Python object attributes &#13;
and methods. Changes on the Python side should update the UI and user inputs on &#13;
the UI should be able to update the model.&#13;
&#13;
### How does it work?&#13;
&#13;
It turns out that Qt's [QtWebkit][3] browser has support for in-process &#13;
communication between its Javascript engine and the running Python application. &#13;
We use this communication channel to create lazily loaded Javascript proxies for Python &#13;
models.&#13;
&#13;
The other nice piece in this story is [AngularJS][2], which provides good model-view &#13;
separation between its HTML template and the corresponding Javascript model. &#13;
AngularJS has great support for two-way data binding between the template and &#13;
the model, which keeps the template expressions always in sync with the JS &#13;
model. This makes sure that the HTML you need to write is terse and simple.&#13;
&#13;
We combine these two pieces to create a lightweight Python-JS bridge which &#13;
provides us the two-way data binding we needed between the Python model and the &#13;
HTML view. We use [Traits][1] to write models in Python. Traits lets us define &#13;
attributes of an object statically, and supports notifications when the &#13;
attributes change. Jigna integrates well with traits so that these notifications automatically &#13;
update the UI. Similarly, user inputs on the UI change model attributes, call &#13;
public methods on the model as well.&#13;
&#13;
Note however that you don&#8217;t need traits to &#13;
use Jigna as you can bind it to your plain old Python objects too - you would &#13;
just need to add your own events *if* you want your models to be updated outside &#13;
of the UI.&#13;
&#13;
### More about the presentation&#13;
&#13;
In the presentation, I will talk about the basic philosophy of Jigna and then &#13;
move on to show some interesting demos. The demos will most likely include the &#13;
following:&#13;
&#13;
* Simple data binding between HTML and traits model&#13;
* A dummy app store UI created using Jigna - It demonstrates multiple &#13;
capabilities of Jigna like: templating lists and objects, calling methods on the &#13;
model, catching events fired on the Python side over in JS side etc.&#13;
* Embedding Qt widgets inside Jigna HTML - we embed [Chaco][4] and [Mayavi][5] &#13;
widgets (Chaco and Mayavi are 2D and 3D visualization libraries respectively) &#13;
which update live as we move HTML sliders.&#13;
* A demo of the web version of Jigna, in which you can view the HTML UI on a web &#13;
browser and execute public methods of the model remotely.&#13;
* WebGL backend working with Jigna (embedding Mayavi in the web version via &#13;
webgl)&#13;
* Embedding Jigna in an [IPython notebook][6] to have interactive plots in &#13;
IPython notebooks.&#13;
&#13;
[1]: http://code.enthought.com/projects/traits/ "Traits"&#13;
[2]: http://angularjs.org/ "AngularJS"&#13;
[3]: http://qt-project.org/wiki/QtWebKit "QtWebkit"&#13;
[4]: http://code.enthought.com/chaco/ "Chaco"&#13;
[5]: http://code.enthought.com/projects/mayavi/ "Mayavi"&#13;
[6]: http://ipython.org/notebook.html "IPython notebook"&#13;
[7]: https://github.com/enthought/jigna "Jigna"</description><speakers><speaker id="215"><name>Prashant Agrawal</name><profile>https://ep2014.europython.eu//en/accounts/profile/215/</profile><image>https://ep2014.europython.eu//site_media/avatars/prashant1.jpg</image></speaker></speakers></entry><entry id="53"><category>Talk</category><audience>Novice</audience><topics><topic>Python Core</topic></topics><start>1000</start><duration>30</duration><room id="4">B09</room><title>PyPy status talk (a.k.a.: no no, PyPy is not dead)</title><description>In this talk we will present the current status of PyPy, with a particular focus on what happened in the last two years, since the last EuroPython PyPy talk.  We will give an overview of the current speed and the on-going development efforts, including but not limited to:&#13;
&#13;
- the status of the Just-in-Time Compiler (JIT) and PyPy performance in general;&#13;
- the improvements on the Garbage Collector (GC);&#13;
- the status of the NumPy and Python 3 compatibility subprojects;&#13;
- CFFI, which aims to be a general C interface mechanism for both CPython and PyPy;&#13;
- a quick overview of the STM (Software Transactional Memory) research project, which aims at solving the GIL problem.&#13;
&#13;
This is the "general PyPy status talk" that we give every year at EuroPython (except last year; hence the "no no, PyPy is not dead" part of the title of this talk).</description><speakers><speaker id="119"><name>Armin Rigo</name><profile>https://ep2014.europython.eu//en/accounts/profile/119/</profile><image>https://ep2014.europython.eu//site_media/avatars/arigo.639x400.png</image></speaker></speakers></entry><entry id="78"><category>Talk</category><audience>Advanced</audience><topics><topic>Other</topic></topics><start>1000</start><duration>30</duration><room id="3">B07/B08</room><title>Amanda: A New Generation of Distributed Services Framework</title><description>Presentation outline&#13;
====================&#13;
&#13;
We'll start off with a quick overview of a movie production pipeline which will set the stage&#13;
for how Amanda provides artists with the tools they need to develop and streamline the production process&#13;
as well as Amanda's crucial function as a robust framework for the support and development teams.&#13;
Going over some stats, up to 250.000 service calls a minute during World War Z for example (for frame of reference this is&#13;
twice the average rate of stackoverflow.com), I'll highlight some of the problems encountered with the 1st generation.&#13;
Initially developed in 2007 and replaced last year it had several flaws in regards to scalability, maintainability and future proofing.&#13;
From there I'll introduce the 2nd generation which is build on the principle of componentisation and building blocks. Every part of the system&#13;
needs to be replaceable and this needs to be possible from the configuration.&#13;
&#13;
During the presentation we will be stepping through the different building blocks, how they have been set up, how they slot together&#13;
and how we monitor, trace and test the system from the ground up. Starting at the lowest level with services we'll slowly&#13;
step through the different blocks necessary to build a fault tolerant, distributed and scalable platform.&#13;
We made sure that the platform is not tied into any specific technology but allows the use of the best technologies&#13;
depending on the type of work being undertaken and changing business needs and technological advances.&#13;
&#13;
Service development and testing&#13;
-------------------------------&#13;
&#13;
Our development teams build applications for artists creating visual effects through to management teams coordinating productions.&#13;
A service-based architecture was chosen to provide consistent interfaces across the many different environments where this is required.&#13;
We provide an ecosystem where developers of any level can safely write a service (a set of instructions regarding a&#13;
specific topic) that are presented to developers and technical artists globally.&#13;
To write a service the developer doesn't need any knowledge in regards to building large concurrent systems.&#13;
The service is implemented through a simple Python API and the provided ecosystem allows services to exist in a standalone manner.&#13;
The service concept was separated from the platform hosting it. This allows hosting in any application that provides a&#13;
standard container (a service provider). Extracting this allowed for more rigorous and simple testing of services;&#13;
it also allows developers to provide fake versions of their services publicly against which client code can be tested.&#13;
The adage &#202;&#187;everything as a service&#202;&#188; was applied to the development of internal facilities.&#13;
This includes our management tools and the developer console, which presents the documentation of services and methods&#13;
available to developers through a web interface.&#13;
Infrastructure services were introduced to present an interface to facilities provided to a regular service, for example&#13;
databases, configuration and centralized logging.&#13;
Services can call other services and, similarly to infrastructures, services can be replaced with different services depending on the configuration.&#13;
Services are exposed to a service (or client as we will see later) via a service provider just like in applications.&#13;
Setting services up with the above patterns allows developers to iterate quickly and to include services within testing frameworks.&#13;
It has also provided a standardized form across projects allowing developers to support and add to unfamiliar code easily.&#13;
And last but not least it has given us full abstractions at all levels, users of services do not need to know the code underneath the hood&#13;
be it at a service level or at an infrastructure level.&#13;
&#13;
&#13;
Building the cluster&#13;
--------------------&#13;
&#13;
Rather than building a single system, the new architecture defines a set of building blocks for constructing a&#13;
distributed service platform. These can provide adapters for best of breed third party tools or, where necessary,&#13;
custom implementations of functionality. Configuration is used to determine the number and types of modules to use&#13;
and the parameters with which to initialize them. This allows the same platform to be used for small instances at&#13;
a developer&#202;&#188;s desk up to a production environment of many nodes. The design enables improved components to be&#13;
swapped into the existing system whilst forming the basis for an entirely new design.&#13;
&#13;
Most practical applications require the service provider to handle multiple requests at the same time.&#13;
Amanda provides a set of interchangeable concurrency modules. This allows the most appropriate Python model&#13;
for parallel processing to be chosen. For work involving heavy I/O work we choose approaches that avoid waiting&#13;
for the GIL, for example multiple processes and greenlets/coroutines, whilst for CPU bound work we can use threads&#13;
which may prove more performant.  Having the option to choose between mechanisms is important since there is not a&#13;
solution that neatly fits all use cases. A pluggable concurrency abstraction also allows integration of new libraries&#13;
as they become available. In future this might include the new asyncio (formerly Tulip) core library for Python 3.3+.&#13;
&#13;
To benefit from concurrency, resource pooling, caching etc. we don't always want to execute the service locally to the service provider.&#13;
Service proxies implement this behavior; they take the service, method and arguments of a request as their input&#13;
and return the result. The proxy should be transparent to the service and service provider components. By chaining&#13;
proxies, complex routing schemes can be built or analysis performed on the results returned. Some similarity can be&#13;
drawn with middle-ware in the Web Services Gateway Interface (WSGI) specification.&#13;
Communication between proxy and service provider is served by the transport. This abstraction provides an&#13;
asynchronous interface to underlying technologies &#226;&#8364;&#8220; Current implementations include queue based AMQP, ontop of&#13;
RabbitMQ, and &#195;&#732;MQ and more na&#195;&#175;ve communications with standard UDP and TCP sockets. Most transports define both client&#13;
and server parts of the system &#226;&#8364;&#8220; however some, particularly HTTP-based transports, are designed to accept requests directly from external clients.&#13;
Requests from external applications commonly use XMLRPC, JSONRPC or straight JSON. Transport implementations can be&#13;
interchanged without impacting other components of Amanda or service developers.&#13;
&#13;
In production, a request gateway implemented as a WSGI application fronts the HTTP protocols. Using the standard&#13;
web components NGINX and &#206;&#188;WSGI we can build a very scalable front end which internally uses the service provider, proxy, transport&#13;
pattern to offload the requests to a backend. The gateway can also provide standard web facilities such as template rendering&#13;
(through the Jinja2 library1) for general web clients. The gateway was a requirement as requests originate from applications&#13;
written in many languages including C++, Python, JavaScript and domain specific languages such as mel. For us it was&#13;
important that the client used across all those languages was a proven standard and lightweight. Most requests are served&#13;
in near realtime (6ms round trip times) and are presented to the client in a synchronous way so using a frontend that supports a large number&#13;
of HTTP like protocols allowed us to keep the clients simple and present the platform to an extremely wide variety of&#13;
languages. Additionally, through the frontend, we can render a web page and present that directly if the requests was made&#13;
from a browser.&#13;
&#13;
The final behavior of the platform is defined in configuration. This allows the platform to be tuned to suit&#13;
the work that a particular service is performing (I/O vs CPU bound). It is important to remember that every single&#13;
component mentioned above be it the concurrency, transport, proxies or frontend can be changed, removed, updated without&#13;
it impacting the service, the developer or any of the other components that make up the platform.&#13;
&#13;
Also important to mention that internally and externally everything is a queue and presented as a queue. Going from the client&#13;
to the frontend there is a queue, from the frontend onto the backend there is a queue etc. all the way down to a request&#13;
being read of the transport and stored inside a queue until a concurrency object is ready to handle the request with the&#13;
service provider.&#13;
&#13;
This is where we think our platform might take a different approach. Rather than building the platform on top of a single&#13;
great technology we didn't want to limit ourselves and be able to use all the other great technologies out there.&#13;
There is no perfect solution for all problems but allowing to fine tune the platform according to different problems.&#13;
The setup can now evolve in line with technological advancements and changes to the industry.&#13;
&#13;
&#13;
Maintenance and Monitoring (5 mins)&#13;
-----------------------------------&#13;
&#13;
We will walk through how we are using the same setup with services, service providers, proxies and transports to manage&#13;
clusters around the globe. Once again for our maintenance and monitoring we made sure everything is done as a service so&#13;
that if there is a better tool in the future we could adopt it.&#13;
&#13;
Through leveraging the configuration management and remote execute platform Salt, a new cluster can now be provisioned quickly.&#13;
Management is itself provided as a service. Through this system, the current state is available and configuration changed across&#13;
all servers globally. This has reduced routine maintenance tasks from a half day to a five-minute task, with less&#13;
chance of human error. Monitoring and introspection are provided, as a service, to aid in day-to-day support, tuning and to help&#13;
support analysis for future development.&#13;
&#13;
Developers of services can trace requests from when they enter the system, producing a report of the sequence of&#13;
methods being called, with the supplied arguments. For each call the time spent to fulfill each request is presented.&#13;
Care was taken to minimize the impact of this on return result of the request. Due to everything being a queue we&#13;
can collect the metrics after the result has been put back onto the transport and send to the user and thus minimize the impact&#13;
of this collection on returning the result of the request&#13;
This means that there is no requirement to put the system into a debug mode in order to obtain execution metrics.&#13;
&#13;
With logging being a service we can dynamically change the logging configuration on a per service basis by making a&#13;
request to the logging service taking away the need of changing configuration and restarting the service which&#13;
often means a problem might have disappeared due to the reset.&#13;
&#13;
Future/Conclusion (1 min)&#13;
-------------------------&#13;
&#13;
Whilst developing the new generation of the platform there have been a number of possible applications that have&#13;
emerged. The way in which we are able to scale the system would be suitable to run in a cloud environment &#226;&#8364;&#8220;&#13;
 especially with the improvements to management allowing new nodes to be provisioned quickly. The ease of writing&#13;
and integrating new components would allow integration with infrastructure provided by third-party cloud vendors.&#13;
Other areas of interest include a smaller version of the platform running locally on a user&#202;&#188;s workstation and&#13;
services for management of generic processes.&#13;
&#13;
Main technologies and libraries currently used:&#13;
------------------------------------------&#13;
&#13;
* Threading&#13;
* Gevent&#13;
* Eventlet&#13;
* Multiprocessing&#13;
* ZeroMQ&#13;
* RabbitMQ&#13;
* uwsgi&#13;
* Flask&#13;
* Salt&#13;
* nginx&#13;
</description><speakers><speaker id="373"><name>Jozef</name><profile>https://ep2014.europython.eu//en/accounts/profile/373/</profile><image>https://ep2014.europython.eu//site_media/avatars/oscar.jpg</image></speaker></speakers></entry><entry id="5"><category>Talk</category><audience>Advanced</audience><topics><topic>Best Practices</topic></topics><start>1000</start><duration>30</duration><room id="1">C01</room><title>Growing Open Source Seeds</title><description>In addition to the abstract above,  here's the full slide deck:&#13;
https://speakerdeck.com/kennethreitz/growing-open-source-seeds&#13;
&#13;
This talk is also based on a blog post, which should give you a great idea of what the talk is about:&#13;
&#13;
http://kennethreitz.org/growing-open-source-seeds/</description><speakers><speaker id="179"><name>kennethreitz</name><profile>https://ep2014.europython.eu//en/accounts/profile/179/</profile><image>https://ep2014.europython.eu//site_media/avatars/kr.png</image></speaker></speakers></entry><entry id="75"><category>Training</category><audience>Novice</audience><topics></topics><start>1000</start><duration>180</duration><room id="6">A03/A04</room><title>Effective data visualisation in 2D with matplotlib</title><description># Introduction&#13;
&#13;
In companies, institutes or at home we generate large amounts of data. A success of our business or research may depend on a proper handling of the data. We can extract &#13;
meaningful patterns by applying data reduction and analysis techniques, but eventually we must present the data graphically. Many software packages allow to create simple line plots or bar charts, but creating data-dense visualisations without distortions is still more of an art than science. The goal of the workshop is to arm you with practice-oriented tips that will help you to avoid clutter and increase the data density of your graphs.&#13;
&#13;
[matplotlib](http://matplotlib.org) is a de facto standard in 2D plotting with Python in active development since 2003. The large number of [visualisation types](http://matplotlib.org/gallery.html) is not matched by any other plotting library available for Python. It can be used to create interactive visualisations, hard copy plots or standalone applications.&#13;
&#13;
The tutorial will introduce the basic theory of data visualisation and put it in use through matplotlib. To unleash the full power of matplotlib, we will reach under the hood and discover some hidden gems in terms of customisation and working with visual primitives. The participants will be encouraged to practice their visualisations skills trough a series of examples. They will learn how to build complex data visualisations from ground up and spice them with a bit of interactivity. &#13;
&#13;
Training objectives:&#13;
&#13;
- use matplotlib for exploratory data analysis,&#13;
- create data-dense and accurate visualisations,&#13;
- prepare your visualisation for presenting&#13;
&#13;
Prerequisites:&#13;
&#13;
- good knowledge of Python at procedural level, experience with object-oriented programming is recommended but not required&#13;
- basic familiarity with [numpy](http://www.numpy.org/) is a plus&#13;
- installed python and matplotlib (for versions and sources see above)&#13;
Website: http://btel.github.io/matplotlib_2014&#13;
&#13;
# About the trainer&#13;
&#13;
Bartosz Telenczuk has a PhD in biophysics. He has been active Python user since 2005. He is creator of [svgutils](https://github.com/btel/svg_utils) and he  has contributed to many open source Python libraries including numpy and matplotlib.  He is also a Python advocate and an instructor at [advanced Python schools for scientists](https://python.g-node.org/python-summerschool-2013/). Currently he is a researcher in France, developing methods to interpret the electrical activity of the brain.&#13;
&#13;
Personal website: http://neuroscience.telenczuk.pl&#13;
</description><speakers><speaker id="710"><name>Bartosz</name><profile>https://ep2014.europython.eu//en/accounts/profile/710/</profile><image></image></speaker></speakers></entry><entry id="82"><category>Training</category><audience>Advanced</audience><topics></topics><start>1000</start><duration>180</duration><room id="7">A05/A06</room><title>Interactive experiments in sound synthesis with Nsound, numpy and matplotlib</title><description>Overview&#13;
--------&#13;
&#13;
This training intends to teach how to experiment with generating sounds and digital signals in an interactive programming and exploration environment provided by [IPython](http://ipython.org/), [matplotlib](http://matplotlib.org/) and the [Nsound](http://nsound.sourceforge.net/) package.&#13;
&#13;
Participants will learn how to generate various waveforms, tones and noises and explore these by listening and easy plotting of various diagrams, all using simple Python code.&#13;
&#13;
&#13;
Topics&#13;
------&#13;
&#13;
* Sound sampling, digital signals and processing&#13;
* Generating and plotting waveforms&#13;
* Loading WAV files&#13;
* Adding sine waves and combining waveforms&#13;
* Producing audio output and WAV files&#13;
* Frequency spectrum diagrams&#13;
* Analyzing harmonic content&#13;
* Mixing Signals&#13;
* Filters&#13;
* Modulation:&#13;
  * Envelopes&#13;
  * Low frequency oscillators (LFOs)&#13;
  * Filter modulation&#13;
* Subtractive synthesis structure&#13;
&#13;
&#13;
Preparation&#13;
-----------&#13;
&#13;
Participants should bring a laptop with Linux (preferred), Windows, or OS X and good headphones. An external audio interface may help with audio performance but is not essential.&#13;
&#13;
Install the following prerequisite software:&#13;
&#13;
* A C/C++ compiler&#13;
  (under debian-like systems, install the 'build-essential' package)&#13;
* Python* (2.7)&#13;
* setuptools (2.x)&#13;
* virtualenv (&gt;= 1.10)&#13;
* Scons (2.3.0)&#13;
* SWIG&#13;
* portaudio*&#13;
&#13;
Any or all of:&#13;
&#13;
  - pygtk* (2.24)&#13;
  - pyqt4*&#13;
  - pyqt5*&#13;
  - wxpython* (3.0)&#13;
&#13;
\* including development headers&#13;
&#13;
Create a virtual environment with Python 2.7 and install the following Python packages and their dependencies:&#13;
&#13;
* Cython (0.20)&#13;
* IPython (1.1.x)&#13;
* matplotlib (1.3.x)&#13;
* numpy (1.8.x)&#13;
* Nsound (0.9.0)&#13;
&#13;
All these, except Nsound, may be installed from PyPI via pip. For Nsound, download the distribution package from its website and follow the installation instructions in the user's guide.&#13;
</description><speakers><speaker id="419"><name>Christopher Arndt</name><profile>https://ep2014.europython.eu//en/accounts/profile/419/</profile><image>https://ep2014.europython.eu//site_media/avatars/chrisarndt_2014_gross.jpg</image></speaker></speakers></entry><entry id="1"><category></category><audience></audience><topics></topics><start>1030</start><duration>30</duration><room>C01, B05/B06, B07/B08, B09, A08</room><title>&#127861; Breakfast</title><description></description><speakers></speakers></entry><entry id="52"><category>Talk</category><audience>Advanced</audience><topics><topic>Python Core</topic></topics><start>1100</start><duration>45</duration><room id="5">A08</room><title>Using All These Cores: Transactional Memory in PyPy</title><description>PyPy is a fast alternative Python implementation.  Software Transactional Memory (STM) is a current academic research topic.  Put the two together --brew for a couple of years-- and we get a version of PyPy that runs on multiple cores, without the infamous Global Interpreter Lock (GIL).&#13;
&#13;
The current research is based on a recent new insight that promises to give really good performance.  The speed of STM is generally measured by two factors: the ability to scale with the number of CPUs, and the amount of overhead when compared with other approaches in a single CPU (in this case, with the regular PyPy with the GIL).  Scaling is not really a problem here, but single-CPU performance is --or used to be. This new approach gives a single-threaded overhead that should be very low, maybe 20%, which would definitely be news for STM systems.  Right now (February 2014) we are still implementing it, so we cannot give final numbers yet, but early results on a small interpreter for a custom language are around 15%.  This looks like a deal-changer for STM.&#13;
&#13;
In the talk, I will describe our progress, hopefully along with real numbers and demos.  I will then dive under the hood of PyPy to give an idea about how it works.  I will conclude with a picture of how the future of multi-threaded programming might looks like, for high-level languages like Python.  I will also mention CPython: how hard (or not) it would be to change the CPython source code to use the same approach.</description><speakers><speaker id="119"><name>Armin Rigo</name><profile>https://ep2014.europython.eu//en/accounts/profile/119/</profile><image>https://ep2014.europython.eu//site_media/avatars/arigo.639x400.png</image></speaker></speakers></entry><entry id="58"><category>Talk</category><audience>Advanced</audience><topics><topic>Web</topic></topics><start>1100</start><duration>45</duration><room id="3">B07/B08</room><title>log everything with logstash and elasticsearch</title><description>The talk will give an overview on how to add centralized, structured logging to a python application running on multiple servers. &#13;
&#13;
It will focus on useful patterns and show the benefits from structured logging. &#13;
</description><speakers><speaker id="722"><name>Peter Hoffmann</name><profile>https://ep2014.europython.eu//en/accounts/profile/722/</profile><image>https://ep2014.europython.eu//site_media/avatars/peter-hoffmann.jpg</image></speaker></speakers></entry><entry id="11"><category>Talk</category><audience>Advanced</audience><topics><topic>Python Core</topic></topics><start>1100</start><duration>45</duration><room id="1">C01</room><title>The Cython Compiler for Python</title><description>The Cython compiler is the most widely used static compiler for Python. The code it generates is used in countless critical applications that process huge amounts of data world wide. Cython has two major use cases: to compile Python code into fast native extension modules, and to connect native code to the CPython runtime. The main goal of the Cython project is to make it easy for users to manually optimise their Python code to make it run at C speed. This talk by one of the core developers will give an intro to using the compiler and an overview of its major features.&#13;
&#13;
Outline will be more or less as follows:&#13;
&#13;
*   Cython: intro to the project and the compiler (4 min.)&#13;
*   compiling Python code&#13;
    -   how to do it and what you get (3 min.)&#13;
    -   a tiny bit of distutils (2 min.)&#13;
*   static typing and Cython extensions to the Python language&#13;
    -   static typing in Cython language syntax (3 min.)&#13;
    -   static typing in pure Python syntax (2 min.)&#13;
    -   why Cython's type system is cool and what users need to know about it (8 min.)&#13;
    -   Cython for optimising Python code (5 min.)&#13;
*   quick intro: talking to native C/C++ code in Cython&#13;
    -   using external C APIs (4 min.)&#13;
    -   using external C++ APIs (3 min.)&#13;
    -   how to build and link in distutils (2 min.)&#13;
    -   notes on ways to wrap large C-APIs (1 min.)&#13;
*   quick overview: special features for high-performance code&#13;
    -   NumPy integration and memory views, fused types, parallel loops in all brevity (3 min.)&#13;
</description><speakers><speaker id="240"><name>Stefan Behnel</name><profile>https://ep2014.europython.eu//en/accounts/profile/240/</profile><image></image></speaker></speakers></entry><entry id="13"><category>Talk</category><audience>Novice</audience><topics><topic>Science</topic></topics><start>1100</start><duration>45</duration><room id="2">B05/B06</room><title>Non Sequitur: An exploration of Python's random module</title><description># Audience&#13;
Non mathematical people who wants a better understanding of Python's random module.&#13;
&#13;
# Objectives&#13;
The audience will understand pseudorandom number generators, the properties of Python's Mersenne Twister and the differences and possible use cases between the distributions provided by the `random` module. &#13;
&#13;
# The talk&#13;
I will start by talking about what randomness means and then about how we try to achieve it in computing through pseudorandom number generators (5 min.)&#13;
&#13;
I will give a brief overview of pseudorandom number generation techniques, show how their quality can be assessed and finally talk about Python's Mersenne Twister and why it is a fairly good choice. (10 min.)&#13;
&#13;
Finally I will talk about how from randomness we can build generators with interesting probability distributions. I'll compare through visualizations thos provided in Python's `random` module and show examples of when they can be useful in real-life. (10 min.)</description><speakers><speaker id="59"><name>Jair Trejo</name><profile>https://ep2014.europython.eu//en/accounts/profile/59/</profile><image>https://ep2014.europython.eu//site_media/avatars/new-profile-pic.jpg</image></speaker></speakers></entry><entry id="43"><category>Talk</category><audience>Novice</audience><topics><topic>Science</topic></topics><start>1100</start><duration>45</duration><room id="4">B09</room><title>RISCy Business: Development of a RNAi design and off-target prediction software</title><description>RISCy Business: Development of a RNAi design and off-target prediction software&#13;
&#13;
Authors: Stefanie Lueck, Tino Kreszies, Patrick Schweizer and Dimitar Douchkov&#13;
&#13;
RNA interference (RNAi) is a sequence similarity-based biological mechanism for inhibiting gene expression. It is initiated by double stranded RNA (dsRNA), which is unusual for eukaryotic cells and normally related to viruses and transposable elements. Generally, if long dsRNA appears in a living cell it will be cut down to short double stranded RNA with a specific size (~20 bp) called small interfering RNA (siRNA). One of the siRNA strands is taken into an enzyme complex named RISC (RNA Induced Silencing Complex), which functions to search and destroy any mRNA that contains sequence complementarity to the siRNA, and thus to inhibit the expression of the gene for the particular mRNA. RNAi has become a valuable research tool for strong and selective suppression of specific genes of interest. However, the application of the technology raises two main questions: 1. Since the recognition of target mRNA is based on sequence similarity, what is the probability of hitting non-targeted genes because they carry stretches of a sequence with high similarity to the siRNA?; 2. What is the optimal design for RNAi constructs? To answer these questions we have created a PyQt-based tool called &#8220;si-Fi&#8221; (si-RNA Finder). Unlike most of the available tools that focus on the siRNA, &#8220;si-Fi&#8221; is specifically designed for long double stranded RNAi constructs that are widely used in non-mammalian systems. The software offers creation of custom sequence databases, flexible search parameters, and provides easy to interpret graphical and tabular outputs. Choosing the PyQt over other GUI toolkits greatly facilitated the development process and made the designing of a reliable and attractive looking cross-platform software accessible for non-professional programmers.</description><speakers><speaker id="63"><name>Stefanie L&#252;ck</name><profile>https://ep2014.europython.eu//en/accounts/profile/63/</profile><image>https://ep2014.europython.eu//site_media/avatars/me.jpg</image></speaker></speakers></entry><entry id="80"><category>Talk</category><audience>Advanced</audience><topics><topic>Best Practices</topic></topics><start>1145</start><duration>45</duration><room id="4">B09</room><title>Support Python 2 and 3 with the same code</title><description>Your library supports only Python 2, - but your users keep nagging you about Python 3 support?&#13;
&#13;
As Python 3 gets adopted more and more, users ask for Python 3 support in existing libraries for Python 2. This talk mentions some approaches for giving users a Python 3 version, but will quickly focus on using the very same code for a Python 2 and a Python 3 version.&#13;
&#13;
This is much easier if you require Python 2.6 and up, and yet a bit easier if you require Python 3.3 as the minimum Python 3 version.&#13;
&#13;
The talk discusses main problems when supporting Python 3 (some are easily solved):&#13;
&#13;
* `print` is a function.&#13;
&#13;
* More Python APIs return iterators that used to return lists.&#13;
&#13;
* There's now a clear distinction between bytes and unicode (text) strings.&#13;
&#13;
* Files are opened as text by default, requiring an encoding to apply on reading and writing.&#13;
&#13;
&#13;
The talk also explains some best practices:&#13;
&#13;
* Start with a good automatic test coverage.&#13;
&#13;
* Deal with many automatic conversions with a one-time 2to3 run.&#13;
&#13;
* Think about how your library should handle bytes and unicode strings. (Rule of thumb: Decode bytes as early as possible; encode unicode text as late as possible.)&#13;
&#13;
* Should you break compatibility with your existing Python 2 API? (Yes, if there's no other way to design a sane API for Python 2 and 3. If you do it, raise the first part of the version number.)&#13;
&#13;
* Try to keep code that's different for Python 2 and 3 minimal. Put code that needs to be different for Python 2 and 3 into a `compat` module. Or use third-party libraries like `six` or `future`.&#13;
&#13;
&#13;
Finally, the talk will mention some helpful resources on the web.</description><speakers><speaker id="673"><name>Stefan Schwarzer</name><profile>https://ep2014.europython.eu//en/accounts/profile/673/</profile><image>https://ep2014.europython.eu//site_media/avatars/StefanSchwarzer.jpg</image></speaker></speakers></entry><entry id="84"><category>Talk</category><audience>Novice</audience><topics><topic>Science</topic></topics><start>1145</start><duration>45</duration><room id="1">C01</room><title>How to become a software developer in science?</title><description>**Goal**: give practical tools for improving skills and software quality to people with a background other than IT.&#13;
&#13;
Eight years ago, as a plant biologist, I knew almost nothing about programming. When I took a course in python programming, I found myself so fascinated that it altered my entire career. I became a scientific software developer. It was long and hard work to get from the level of 'Hello world' to the world of software development. The talk will cover how to embrace a non-IT education as a strength, how and why to atomize programming tasks and the importance of doing side projects.&#13;
&#13;
### 1. Embrace your background&#13;
Having domain specific knowledge from a field other than IT helps you to communicate with the team, the users and the group leader. It prevents misunderstandings and helps to define features better. A key step you can take is systematically apply the precise domain specific language to the code e.g when naming objects, methods or functions. Another is to describe the underlying scientific process step by step as a Use Case and write it down in pseudocode.&#13;
&#13;
### 2. Atomisation&#13;
Having a set of building block in your software helps to define responsibilities clearly. Smaller parts are easier to test, release and change. Modular design makes the software more flexible and avoids the Blob and Lava Flow Anti-Patterns. When using object oriented programming a rule of thumb is that an object (in Python also a method) does only one thing. You can express this Single Responsibility Principle as a short sentence for each module. Another practical action is to introduce Design Patterns that help to decouple data and its internal representation. As a result, your software becomes more flexible.&#13;
 &#13;
### 3. Participating in side projects&#13;
Learning from others is a great opportunity to grow. Through side projects you gain a fresh perspective and learn about best practices in project management. You gain new ideas for improvement and become aware of difficulties in your own project. You can easily participate in a scientific project by adding a small feature, writing a test suite or provide a code review on a part of a program.&#13;
&#13;
Summarizing, in scientific software development using domain-specific knowledge, atomisation of software, and participation in side projects are three things that help to create high quality software and to continuously improve as a developer.&#13;
&#13;
The talk will address challenges in areas where science differs from the business world. It will present general solution one might use for software developed in a scientific environment for research projects rather then discussing particular scientific packages. &#13;
&#13;
### Qualifications&#13;
During my PhD I developed a software on 3D RNA modeling (www.genesilico.pl/moderna/) that resulted in 7 published articles. I am coauthor on a paper on bioinformatic software development. Currently I am actively developing a system biology software in Python at the Humboldt University Berlin (www.rxncon.org).</description><speakers><speaker id="353"><name>Magdalena Rother</name><profile>https://ep2014.europython.eu//en/accounts/profile/353/</profile><image>https://ep2014.europython.eu//site_media/avatars/MRother_photo_2.png</image></speaker></speakers></entry><entry id="46"><category>Talk</category><audience>Novice</audience><topics><topic>Science</topic></topics><start>1145</start><duration>45</duration><room id="5">A08</room><title>Storing scientific data with HDF5</title><description>As a scientist (or system administrator) you usually generate a lot of data&#13;
with your experiments or when you monitor simulated or real systems. Python&#13;
offers a great variety of options to store that data.&#13;
&#13;
In this talk, I&#8217;m going to explore sme of them and demonstrate them with small&#13;
examples. &#13;
&#13;
The main part will be about HDF5 and its Python interface h5py (which&#13;
I&#8217;ll briefly compare to PyTables). &#8220;HDF5 is a data model, library, and file format for storing and managing data.&#8220; (http://www.hdfgroup.org/HDF5/) Unlike relational databases, datasets are stored hierarically (like files in nested folders). HDF5 supports large a mounts of data, many datatypes and many platforms/languages making it a very versatile and useful tool.&#13;
&#13;
Finally, I&#8217;ll compare the different&#13;
approaches in terms of ease of use, writing performance, disk usage, memory&#13;
consumption and reading/analysis. I&#8217;ll also try to give advice which technique&#13;
works best in which situation.&#13;
&#13;
Structure of the talk (20min talking + 5min discussion + 5min buffer):&#13;
&#13;
* Motivation (2min)&#13;
* Brief examples: (5min)&#13;
    * Trivial: Store (CSV) files&#13;
    * "Real" database with SQL, e.g. Sqlite (built-in)&#13;
    * Management-friendly: Writing Excel files&#13;
    * Dumping NumPy arrays to disk&#13;
* The scientist&#8217;s way: Using HDF5 (8min)&#13;
    * Brief comparison between h5py and PyTables&#13;
    * Introduction to h5py&#13;
* Comparison of all approaches (easy of use, writing performance, reading&#13;
  performance, memory consumption, disk usage) (3min)&#13;
* Conclusion (2min)&#13;
&#13;
The overall goal of this talk is to give an overview over the various&#13;
techniques to enable the audience to make an educated decision next time they&#13;
need to store a bigger amount of data. I hope to show that HDF5 is usually a&#13;
good choice if the requirements don&#8217;t demand something else.</description><speakers><speaker id="368"><name>Stefan</name><profile>https://ep2014.europython.eu//en/accounts/profile/368/</profile><image>https://ep2014.europython.eu//site_media/avatars/ssc1.jpg</image></speaker></speakers></entry><entry id="69"><category>Talk</category><audience>Advanced</audience><topics><topic>Science</topic></topics><start>1145</start><duration>45</duration><room id="2">B05/B06</room><title>Ganga: an interface to the LHC computing grid</title><description>[Ganga](https://cern.ch/ganga) is a tool, designed and used by the large particle physics experiments at CERN. Written in pure Python, it delivers a clean, usable interface to allow thousands of physicists to interact with the huge computing resources available to them. It provides a single platform with which data analysis tasks can be run on anything from a local machine to being distributed seamlessly to computing centres around the world.&#13;
&#13;
The talk will cover the problems faced by physicists when dealing with the computer infrastructure and how Ganga helps to solve this problem. It will focus on how Python has helped create such a tool through its advanced features such as metaclasses and integration into IPython.</description><speakers><speaker id="693"><name>Matt Williams</name><profile>https://ep2014.europython.eu//en/accounts/profile/693/</profile><image></image></speaker></speakers></entry><entry id="85"><category>Talk</category><audience>Advanced</audience><topics><topic>Science</topic></topics><start>1145</start><duration>45</duration><room id="3">B07/B08</room><title>Probabilistic Programming in Python</title><description>Probabilistic Programming allows flexible specification of statistical models to gain insight from data. Estimation of best fitting parameter values, as well as uncertainty in these estimations, can be automated by sampling algorithms like Markov chain Monte Carlo (MCMC). The high interpretability and flexibility of this approach has lead to a huge paradigm shift in scientific fields ranging from Cognitive Science to Data Science and Quantitative Finance.&#13;
&#13;
PyMC3 is a new Python module that features next generation sampling algorithms and an intuitive model specification syntax. The whole code base is written in pure Python and Just-in-time compiled via Theano for speed.&#13;
&#13;
In this talk I will provide an intuitive introduction to Bayesian statistics and how probabilistic models can be specified and estimated using PyMC3.</description><speakers><speaker id="761"><name>Thomas Wiecki</name><profile>https://ep2014.europython.eu//en/accounts/profile/761/</profile><image>https://ep2014.europython.eu//site_media/avatars/tw3.jpg</image></speaker></speakers></entry><entry id="4"><category></category><audience></audience><topics></topics><start>1230</start><duration>90</duration><room>C01, B05/B06, B07/B08, B09, A08</room><title>&#127860; Lunch</title><description></description><speakers></speakers></entry><entry id="7"><category>Talk</category><audience>Novice</audience><topics><topic>Best Practices</topic></topics><start>1400</start><duration>30</duration><room id="2">B05/B06</room><title>The Sorry State of SSL</title><description>The rule of thumb for people without degrees in cryptography on securing data on the Internet is &#8220;GPG for data at rest. TLS for data in motion&#8221;. And it&#8217;s actually a very good rule everyone should follow.&#13;
&#13;
The only kicker though is that configuring (and using!) TLS properly is not as simple as it sounds and if you&#8217;re not diligent as a user, developer, and ops engineer, you can easily compromise your data&#8217;s security despite best effort of everyone else.&#13;
&#13;
This talk will be multifaceted; you will learn:&#13;
&#13;
- how SSL and TLS roughly work and why their state is sorry,&#13;
- server- and client-side duties for best possible security,&#13;
- what alternatives you have for using TLS in Python,&#13;
- things to keep in mind when configuring servers,&#13;
- and what perils outside your control still can trip you up.&#13;
&#13;
In other words, the leitmotif is to show you the most common traps you should know about when using and deploying applications relying on TLS for transport layer security and how to avoid them. </description><speakers><speaker id="183"><name>Hynek</name><profile>https://ep2014.europython.eu//en/accounts/profile/183/</profile><image>https://ep2014.europython.eu//site_media/avatars/avatar_hs.jpg</image></speaker></speakers></entry><entry id="25"><category>Talk</category><audience>Advanced</audience><topics><topic>Other</topic></topics><start>1400</start><duration>30</duration><room id="1">C01</room><title>Multiplatform binary packaging and distribution of your client apps</title><description>This talk aims to propose an easy way of packaging python applications that meet to requirements: It&#8217;s stand-alone (no need to install python in the client) and code is obfuscated. &#13;
&#13;
&#13;
Python obfuscation is a recurrent topic in forums and discussion lists. However, answers are, most of the time, on the line of discouraging doing so; either because it violates some ethics principle or because it is said to be hard or non cost-effective.&#13;
&#13;
&#13;
Proposed solution is a fully automated process that goes through following buildbot pipeline:&#13;
&#13;
-  Native python extensions are built with Cython for every platform we&#8217;re distributing for, using clang, MS Visual and gcc as compilers.&#13;
-  These extensions along with external dependencies are packaged with PyInstaller. Dependencies are automatically gathered from requirements.txt files and spec file is created on the fly to include resources such as image or text files.&#13;
-  Platform specific installers are built to distribute the app using pkgbuild and productbuild for MacOS, dpkg-deb for Ubuntu and Raspbian and InnoSetup for Windows.&#13;
-  Installers are uploaded by Buildbot to Amazon S3 to a version specific folder.&#13;
&#13;
&#13;
I will also give a little introduction to used tools such as Cython, Buildbot and Pyinstaller, discuss problems encountered and how they were solved and talk about performance impact.&#13;
</description><speakers><speaker id="35"><name>juliass</name><profile>https://ep2014.europython.eu//en/accounts/profile/35/</profile><image>https://ep2014.europython.eu//site_media/avatars/julia-galicia.jpg</image></speaker><speaker id="405"><name>Diego</name><profile>https://ep2014.europython.eu//en/accounts/profile/405/</profile><image>https://ep2014.europython.eu//site_media/avatars/cara_alegre.jpg</image></speaker></speakers></entry><entry id="6"><category>Talk</category><audience>Advanced</audience><topics><topic>Testing</topic></topics><start>1400</start><duration>30</duration><room id="5">A08</room><title>Don't fear our new robot overlords!</title><description>GoldenEye is our solution for mobile front end tests. Testing on mobile devices can be quite devastating: On iOS you can write front test in JavaScript in Instruments but it is quite impossible to connect Instruments to you CI solution of choice. On Android the situation isn't much better.&#13;
Other front end test frameworks can work with mobile devices (or simulators) but they lack the ability to see. Of course you can check if a color is set correctly, if a frame has the right x and y coordinates but in a world of different screen sizes writing these tests can be quite challenging as well.&#13;
In the end you will always need to look on your screen again and again trying to spot any issues. &#13;
&#13;
GoldenEye takes a different approach. It does not need to run on your development computer, you don't need a Mac for running tests on iOS devices and you can have real touches on your controls. This is archived by using openCV and it's python bindings, Pythons's unittest module and the Tapsterbot, an OpenSource delta robot made with 3D printing and an Arduino controller. To write a test you just take some screenshots on your device, cut out the icons you need to tap or inspect and write a very simple unit test using a high-level API that takes away the hard parts.&#13;
&#13;
WARNING: This talk features a real robot. In case of machine world-domination: RUN!</description><speakers><speaker id="165"><name>plaetzchen</name><profile>https://ep2014.europython.eu//en/accounts/profile/165/</profile><image>https://ep2014.europython.eu//site_media/avatars/avatar_neu_klein.png</image></speaker></speakers></entry><entry id="95"><category>Talk</category><audience>Advanced</audience><topics><topic>Other</topic></topics><start>1400</start><duration>30</duration><room id="3">B07/B08</room><title>Open Source isn't for everyone, but it could be</title><description>Much of my work over the past year has been talking about how we can increase diversity and inclusion in all of our spaces. This talk will focus on how we, as OSS contributors, can create a better experience for everyone wanting to contribute to our projects, including making more plainly visible how and what to contribute and encouraging the use of codes of conduct.&#13;
&#13;
# Structure of the talk:&#13;
*    the state of open source right now&#13;
    *    statistics about the lack of diversity&#13;
*    why the low representation?&#13;
    *    time&#13;
    *    pay inequality&#13;
    *    few compensated for OSS&#13;
    *    poor treatment&#13;
*    what can i do to make OSS open to more kinds of contributors?&#13;
    *    make it obvious&#13;
    *    make it easy&#13;
    *    vulnerability&#13;
    *    patience&#13;
    *    helpful&#13;
    *    safety&#13;
    *    compensate&#13;
    *    volunteer&#13;
*    resources</description><speakers><speaker id="306"><name>Ashe Dryden</name><profile>https://ep2014.europython.eu//en/accounts/profile/306/</profile><image>https://ep2014.europython.eu//site_media/avatars/pink_Feb2014.jpg</image></speaker></speakers></entry><entry id="50"><category>Talk</category><audience>Expert</audience><topics><topic>Best Practices</topic></topics><start>1400</start><duration>30</duration><room id="4">B09</room><title>Test Driven Infrastructure</title><description>Common wisdom has it that the test effort should be related to the risk of a change. However, the reality is different: Developers build elaborate automated test chains to test every single commit of their application. Admins regularly &#8220;test&#8221; changes on the live platform in production. But which change carries a higher risk of taking the live platform down?&#13;
&#13;
What about the software that runs at the &#8220;lower levels&#8221; of your platform, e.g. systems automation, provisioning, proxy configuration, mail server configuration, database systems etc. An outage of any of those systems can have a financial impact that is as severe as a bug in the &#8220;main&#8221; software!&#13;
One of the biggest learnings that any Ops person can learn from a Dev person is Test Driven Development. Easy to say - difficult to apply is my personal experience with the TDD challenge.&#13;
&#13;
This talk throws some light on recent developments at ImmobilienScout24 that help us to develop the core of our infrastructure services with a test driven approach:&#13;
&#13;
* How to do unit tests, integration tests and systems tests for infrastructure services?&#13;
* How to automatically verify Proxy, DNS, Postfix configurations before deploying them on live servers?&#13;
* How to test &#8220;dangerous&#8221; services like our PXE boot environment or the automated SAN mounting scripts?&#13;
* How to add a little bit of test coverage to everything we do.&#13;
* Test Driven: First write a failing test and then the code that fixes it.&#13;
&#13;
The tools that we use are Bash, Python, Unit Test frameworks and Teamcity for build and test automation.&#13;
&#13;
See http://blog.schlomo.schapiro.org/2013/12/test-driven-infrastructure.html for more about this topic.&#13;
</description><speakers><speaker id="696"><name>Schlomo Schapiro</name><profile>https://ep2014.europython.eu//en/accounts/profile/696/</profile><image>https://ep2014.europython.eu//site_media/avatars/Schlomo_Schapiro_Large.jpg</image></speaker></speakers></entry><entry id="49"><category>Training</category><audience>Novice</audience><topics></topics><start>1400</start><duration>180</duration><room id="6">A03/A04</room><title>An intro to Blender modeling and scripting </title><description>This training introduces you to the marvelous world of Blender, the popular opensource 3d computer graphics software. The goal is to create step by step some stunning 3d art by the end of the training giving you the knowledge to start having fun with Blender and python.</description><speakers><speaker id="110"><name>synasius</name><profile>https://ep2014.europython.eu//en/accounts/profile/110/</profile><image>https://ep2014.europython.eu//site_media/avatars/gravatar_1.jpeg</image></speaker></speakers></entry><entry id="70"><category>Training</category><audience>Novice</audience><topics></topics><start>1400</start><duration>180</duration><room id="7">A05/A06</room><title>Learn Test-Driven-Development and Django by building a simple web application from scratch.</title><description>We'll cover unit testing, Django models, views and templates, as well as using Selenium to open up a real web browser for functional tests.&#13;
This talk is intended for audiences new to TDD, new to Django, and even new to Python!&#13;
&#13;
The aim is to cover the basics of setting up a simple Django site, but using full, rigorous TDD at every step along the way.&#13;
The material covered in this training is all available online as part of Harry Percival's great book ["Obey the testing goat"](http://chimera.labs.oreilly.com/books/1234000000754)&#13;
&#13;
&#13;
We'll learn how to set up functional tests with Selenium, how to set up Django, how to run Django unit tests, how TDD actually works in practice, the unit test / code cycle where we re-run the tests after each tiny, incremental change to the code, as well as all the basics of Django.&#13;
We'll talk about what to test, what not to test, what the point of all this testing is anyway, and I promise to make it all at least moderately entertaining.&#13;
&#13;
Plus it's all in Python 3!&#13;
&#13;
It is absolutely vital that you come with the required software pre-installed on your PC.&#13;
&#13;
So, make sure you have the following installed on your Mac/Linux machine:&#13;
&#13;
- Python  3.3&#13;
- Git&#13;
- Firefox&#13;
- Selenium&#13;
- Django &gt;= 1.6&#13;
&#13;
Have a look at the section of the book for the [required software installations](http://chimera.labs.oreilly.com/books/1234000000754/pr02.html#_required_software_installations) for more detailed instructions.&#13;
</description><speakers><speaker id="251"><name>andrea crotti</name><profile>https://ep2014.europython.eu//en/accounts/profile/251/</profile><image>https://ep2014.europython.eu//site_media/avatars/andrea_face_1.jpg</image></speaker></speakers></entry><entry id="96"><category>Talk</category><audience>Advanced</audience><topics><topic>Other</topic></topics><start>1430</start><duration>30</duration><room id="4">B09</room><title>Green Celery and the Async Sweet Spot</title><description>Celery is a distributed task orchestration framework for Python, with an amazing set of features and supported backends.&#13;
&#13;
Gevent is a non-blocking I/O library for Python which seems to magically turn your synchronous programs asynchronous, with the help of the greenlet library under the hood.&#13;
&#13;
Did you know you can easily combine the two, with inbuilt support for a Gevent event loop in Celery itself, you too can achieve distributed async tasks across thousands of nodes and not get lost in a see of callbacks.&#13;
&#13;
Follow me as I show you all the considerations, drawbacks, and tips for Celery+greenlet+Gevent bliss, from working with I/O vs CPU blocking tasks, to managing resource starvation and queue contention, and going beyond the Celery API to take advantage of the Gevent API.</description><speakers><speaker id="340"><name>Wes Mason</name><profile>https://ep2014.europython.eu//en/accounts/profile/340/</profile><image>https://ep2014.europython.eu//site_media/avatars/av400.jpeg</image></speaker></speakers></entry><entry id="72"><category>Talk</category><audience>Advanced</audience><topics><topic>Python Core</topic></topics><start>1430</start><duration>30</duration><room id="5">A08</room><title>Extending Python, what is the best option for me?</title><description>In this talk we will explore all the alternatives in cpython ecosystem to load external libraries. In first place we'll study the principles and how shared libraries work. After that we will look into the internals of CPython to understand how extensions work and how modules are loaded. Then we will study the main three alternatives to extend CPython: Native Extensions, Ctypes and CFFI and how to automate the process. &#13;
Furthermore we will take a look to other python implementations and how we can extend it.</description><speakers><speaker id="175"><name>Francisco Fern&#225;ndez Casta&#241;o</name><profile>https://ep2014.europython.eu//en/accounts/profile/175/</profile><image>https://ep2014.europython.eu//site_media/avatars/foto.jpeg</image></speaker></speakers></entry><entry id="94"><category>Talk</category><audience>Novice</audience><topics><topic>Best Practices</topic></topics><start>1430</start><duration>30</duration><room id="2">B05/B06</room><title>The ideal REST API for the AngularJS applications</title><description>## Motivation&#13;
&#13;
I became interested in AngularJS framework about a year ago, as a part of my graduate studies at Georgia Tech. I have been following this amazing technology development ever since.&#13;
&#13;
With a recent trend of Single Page Apps (SPAs) becoming more and more sophisticated and more widely accepted, it is necessary to revisit our REST API design and implementation strategies. &#13;
&#13;
While REST style has been around for quite some time, it is still considered informal and only vaguely understood, which is probably because not many of us developers have actually spent time reading Fielding's dissertation (including me, until some time ago). &#13;
&#13;
Recently I have finished designing backend specifications for relatively complex AngularJS application (it deals with event management, and is scheduled for beta later on this year). &#13;
&#13;
In this talk, I want to share my insights on designing and implementing non-trivial REST API to fully utilize AngularJS stack.&#13;
&#13;
## Format&#13;
&#13;
The talk will not be a REST 101, as I will concentrate on specific *practical* problems that arise when implementing backend API.&#13;
&#13;
During the talk, I will walkthrough the audience through the process of building simple AngularJS app, with all necessary REST backend implemented on top of the Flask framework.&#13;
&#13;
Each topic, that we will discuss, will be presented as a three section block: &#13;
&#13;
- a) Problem Postulation &#13;
- b) Proposed Implementation &#13;
- c) Pitfalls, Gotchas and Tips.&#13;
&#13;
**Note:** Flask is used as illustration, therefore techniques I present are almost framework-agnostic, as the micro-framework imposes quite a few requirements on a developer. My aim is to make sure that examples are easily adaptable to your framework of choice.&#13;
&#13;
## Topic Covered&#13;
&#13;
Here is a rough outline of topics/themes that I will cover (it is what I am working on now, list can probably be expanded, but only slightly):&#13;
&#13;
- CRUD (emphasis on integration with Form processing facilities of AngularJS)&#13;
- Designing URLs (Interconnecting with AngularJS navigation)&#13;
- Content Negotiation (language, representation format)&#13;
- Security (both Authentication and Authorization)&#13;
- Caching&#13;
- API Testing (including load testing)&#13;
- API Extension and Versioning&#13;
- Beyond CRUD: Collections + Querying&#13;
&#13;
## Target Audience&#13;
&#13;
I expect people be familiar with Python (obviously). Additionally, I expect people to have basic knowledge of the REST architecture style (to get most out of the talk)&#13;
&#13;
No prior familiarity with AngularJS is expected (I will provide some quick overview of the framework w/i talk).&#13;
&#13;
Anyone interested in exploring what AngularJS framework has to offer, should benefit from this talk.&#13;
&#13;
## Extra notes&#13;
&#13;
I can present the talk as 180min. tutorial or as a long talk. The former will have more hands-on approach in it. &#13;
&#13;
It will be same when it comes to topics covered, but we will have more time to actually practice creating sample AngularJS application and necessary backend API in real-time.&#13;
&#13;
Additionally, if it is better to present the topic as tutorial, we will cover some best practices of AngularJS application creation too e.g. using conventional toolset (yeoman, grunt, bower etc).</description><speakers><speaker id="41"><name>Victor Farazdagi</name><profile>https://ep2014.europython.eu//en/accounts/profile/41/</profile><image>https://ep2014.europython.eu//site_media/avatars/farazdagi-codefest.jpg</image></speaker></speakers></entry><entry id="14"><category>Talk</category><audience>Novice</audience><topics><topic>System Administration</topic></topics><start>1430</start><duration>30</duration><room id="1">C01</room><title>Statistics 101 for System Administrators</title><description>#Statistics 101 for System Administrators&#13;
&#13;
## Agenda&#13;
 * A latency issue&#13;
 * Data distribution&#13;
 * 30 seconds correlation with pearsonr&#13;
 * Combinating data&#13;
 * Plotting and the power of color&#13;
&#13;
## An use case &#13;
 - Network latency issues&#13;
 - Correlate latency with other events &#13;
    &#13;
## First statistics &#13;
 - we created our parsing library &#13;
 - [using various recipes](http://chimera.labs.oreilly.com/books/1230000000393/ch06.html)&#13;
 - Having the data in a dict like&#13;
&#13;
        &gt; table = {&#13;
        &gt;   'time': [ 1,2,3, ..],&#13;
        &gt;   'elapsed': [ 0.12, 12.43, ..],&#13;
        &gt;   'error': [ 2, 0, ..],&#13;
        &gt;   'size': [123,3223, ..],&#13;
        &gt;   'peers': [2313, 2303, ..],&#13;
&#13;
 - It's easy to get max, min and standard deviation&#13;
&#13;
        &gt; print [k, max(v), min(v), stats.mean(v) ] for k,v in table.items() ]&#13;
&#13;
## Distribution &#13;
 - A distribution shows event frequency &#13;
&#13;
        &gt; from matplotlib import pyplot&#13;
        &gt; pyplot.hist(table['elapsed'])&#13;
&#13;
 - Time and Size distributions&#13;
&#13;
## (Linear) Correlation &#13;
 - What's correlation&#13;
 - What's not correlation&#13;
 - pearsonr and probability&#13;
 - catch for linear correlation&#13;
&#13;
        &gt; from scipy.stats.stats import pearsonr&#13;
        &gt; a, b = range(0,10), range(0,20, 2)&#13;
        &gt; c = [randint(0,10) for x in a]&#13;
        &gt; pearsonr(a, b), pearsonr(a,c)&#13;
        &gt; (1.0, 0.0), (0.43, 0.2)&#13;
&#13;
## Combinations &#13;
 - using itertools.combinations&#13;
 - netfishing correlation&#13;
&#13;
        &gt;from itertools import combination&#13;
        &gt;for f1, f2 in combinations(table, 2):&#13;
        &gt;        r, p_value = pearsonr(table[f1], table[f2])&#13;
        &gt;        print("the correlation between %s and %s is: %s" % (f1, f2, r))&#13;
        &gt;        print("the probability of a given distribution (see manual) is: %s" % p_value)&#13;
&#13;
## Plot always &#13;
&#13;
 - pearsonr finds *only* linear correlation&#13;
 - our eyes work better :P&#13;
 - so...plot always!&#13;
 - color is the 3d dimension of a plot!&#13;
&#13;
        &gt; from pyplot import scatter, title, xlabel, ylabel, legend&#13;
        &gt; from pyplot import savefig, close as closefig&#13;
        &gt;&#13;
        &gt; for f1, f2 in combinations(table, 2):&#13;
        &gt;    scatter(table[f1], table[2], label="%s_%s" % (f1,f2))&#13;
        &gt;    # add legend and other labels&#13;
        &gt;    r, p = pearsonr(table[f1], table[f2])&#13;
        &gt;    title("Correlation: %s v %s, %s" % (f1, f2, r))&#13;
        &gt;    xlabel(f1), ylabel(f2)&#13;
        &gt;    legend(loc='upper left') # show the legend in a suitable corner&#13;
        &gt;    savefig(f1 + "_" + f2 + ".png")&#13;
        &gt;    closefig()&#13;
&#13;
 &#13;
## Wrap Up! &#13;
 - do not use pearsonr to *exclude* relation between events&#13;
 - plots may serve better&#13;
 - scatter plot can show a system thruput and exclude correlation between fields A and fields B&#13;
 - continue collecting results&#13;
 &#13;
&#13;
</description><speakers><speaker id="248"><name>Roberto Polli</name><profile>https://ep2014.europython.eu//en/accounts/profile/248/</profile><image>https://ep2014.europython.eu//site_media/avatars/rpolli_400.jpg</image></speaker></speakers></entry><entry id="86"><category>Talk</category><audience>Novice</audience><topics><topic>Web</topic></topics><start>1430</start><duration>30</duration><room id="3">B07/B08</room><title>How to make a full fledged REST API with Django OAuth Toolkit</title><description>The talk aims to explain how to create a RESTful API protected with OAuth2. The tools used are the popular web framework Django, Django Rest Framework app to create the REST enpoints and Django OAuth Toolkit, an app powered by the most known oauthlib that provides the OAuth2 authorization flow, token exchange and endpoint protection.</description><speakers><speaker id="110"><name>synasius</name><profile>https://ep2014.europython.eu//en/accounts/profile/110/</profile><image>https://ep2014.europython.eu//site_media/avatars/gravatar_1.jpeg</image></speaker></speakers></entry><entry id="55"><category>Talk</category><audience>Novice</audience><topics><topic>Gaming</topic></topics><start>1500</start><duration>30</duration><room id="2">B05/B06</room><title>3D sensors and Python: A space odyssey</title><description>This talk will start with a brief introduction to 3D Sensors and OpenNI. Then we&#8217;ll surf into PyOpenNI,  features such as the skeleton, hand and gesture tracking, RGB and depth video. Every topic will be presented with practical demos. The talk will end with a demo integrating WebGL (THREE.JS), 3D sensors, Flask and ZMQ to produce a simple fully open source based NUI game.&#13;
&#13;
Some simple demos of PyOpenNI and PyGame can be found at [1](http://www.youtube.com/watch?v=wI2ktioiPY8) and [2](http://youtu.be/3e8jibGUQ2Q)&#13;
&#13;
Attendees will not only learn about game related technologies but also about innovative ways of doing domotics, cinema &amp; art, Interactive visualization, scientific research, educations, etc.&#13;
&#13;
3D Sensors will be available for testing during the event - you can get yours for about 80 to 140 Euros (depending on the brand). Slides and demo code will be available at Github.&#13;
&#13;
Talk structure:&#13;
&#13;
* Introduction: hardware and OpenNI goodies and a tale of PCL (5&#8217;)&#13;
* Hands On PyOpenNI&#13;
    * Normal and Depth camera - basics concepts and small demo (5&#8217;)&#13;
    * Skeleton - basics concepts and small demo. (5&#8217;)&#13;
	* Hand &amp; gesture - basics concepts and small demo. (5&#8217;)&#13;
* Final Demo&#13;
	* What we&#8217;re going to use? Flask, ZMQ, THREE.JS, PyOpenNI. (6&#8217;)&#13;
* Q&amp;A. (4&#8217;)</description><speakers><speaker id="55"><name>Celia</name><profile>https://ep2014.europython.eu//en/accounts/profile/55/</profile><image>https://ep2014.europython.eu//site_media/avatars/joRamone_1.jpg</image></speaker></speakers></entry><entry id="51"><category>Poster</category><audience>Novice</audience><topics><topic>Science</topic></topics><start>1500</start><duration>30</duration><room></room><title>Meta-estimators and advanced machine-learning pipelines</title><description>We will discuss some of our *meta-estimators* implementing the Scikit-learn &#13;
interface, including&#13;
&#13;
* cross validation of time-series estimators&#13;
* transformer-only pipeline&#13;
* more general hyperparameter optimization&#13;
* GroupBy meta-estimator&#13;
* meta-estimators for restricting subestimators to a subset of columns or rows&#13;
&#13;
in the context of different machine learning problems.&#13;
The poster is closely related to the talk &#13;
"Ideas for extensions to scikit-learn and its interface".&#13;
</description><speakers><speaker id="701"><name>Martin</name><profile>https://ep2014.europython.eu//en/accounts/profile/701/</profile><image></image></speaker><speaker id="445"><name>B. Daniel</name><profile>https://ep2014.europython.eu//en/accounts/profile/445/</profile><image></image></speaker></speakers></entry><entry id="56"><category>Talk</category><audience>Novice</audience><topics><topic>Best Practices</topic></topics><start>1500</start><duration>30</duration><room id="4">B09</room><title>Traversing Mazes the pythonic way and other Algorithmic Adventures</title><description>Programming isn't just about software architectures and object-oriented design;&#13;
it is also about solving algorithmic problems *efficiently*, some of which &#13;
are really *hard* [[Hetland, 2010]][0].&#13;
&#13;
The way we decide to *represent* and to *solve* our problems &#13;
(i.e., the *data structure* and the *algorithm* we use, respectively)&#13;
has a great impact on the overall *complexity* of our solution.&#13;
&#13;
In this scenario, **graphs** define a powerful mental (and mathematical)&#13;
model to deal with many algorithmic problems: "if we can formulate a problem as &#13;
one dealing with graphs, even if it doesn't *look* like a graph problem, we &#13;
are probably one step closer to solving it." [[Hetland, 2010]][0].&#13;
&#13;
Indeed, graphs constitute the building blocks for many (*hard*) problems. &#13;
Thus, mastering graphs and graph algorithms (e.g., graph traversals) provides a &#13;
jump start to deal with many other problems, such as *The Traveling Salesman* problem &#13;
(a.k.a. `TSP`), or *finding the shortest path to get out from a dungeon in a `D&amp;D` &#13;
story* [^1].	&#13;
&#13;
With particular considerations to the authoritative books on this subject (such &#13;
as the classics by *T. Cormen* and *R. Sedgewick*) for the theoretical &#13;
part (actually intended to be very limited and mostly referenced), this talk &#13;
aims at providing an overview of graphs and main graph-based algorithms for &#13;
Python programmers.&#13;
&#13;
The general outline of the talk will cover the following topics:&#13;
&#13;
*    Implementing Graphs and Trees;&#13;
*    "DRY" Algorithms&#13;
    *    "Memoization" and "Dynamic Programming"&#13;
*    "Mazes" Traversals and Search&#13;
    *    Graph Traversals&#13;
    *    Shortest Path Algorithms&#13;
*    "Hard" Graph Problems&#13;
    *    TSP&#13;
    *    Graph Colouring and Vertex Cover&#13;
&#13;
The main goal of the talk is to analyse how one of the most fundamental (data)&#13;
structure of "ADS" university classes, may be handled (and implemented) in a &#13;
**very pythonic way**, in accordance with the [Zen of Python][1] (e.g., &#13;
*beautiful is better than ugly*, *simple is better than complex*, *readability counts*).&#13;
&#13;
Moreover, since the Python ecosystem now offers several libraries and tools to deal&#13;
with graph representations and manipulations, e.g., [`networkx`](http://networkx.github.io)&#13;
or [`PADS`](http://www.ics.uci.edu/~eppstein/PADS/), references and comparisons with existing &#13;
implementations will be provided in order to analyse and compare existing solutions, while&#13;
*avoiding re-inventing the wheel*.&#13;
&#13;
To this end, code examples and case studies will be presented during the talk&#13;
to encourage the discussion and to stimulate the attendees to come up with &#13;
different solutions.&#13;
&#13;
Very basic math skills are required, together with familiarity with programming&#13;
in general and with Python in particular.&#13;
&#13;
[0]: http://goo.gl/ZeuDNc "Hetland, M. L., Python Algorithms, Mastering the Basic Algorithms in the Python Language, Apress 2010"&#13;
[1]: http://www.python.org/dev/peps/pep-0020/ "PEP20: The Zen of Python"&#13;
&#13;
[^1]: "Please replace D&amp;D with your favourite RPG. D&amp;D may sound old fashioned :)"</description><speakers><speaker id="250"><name>Valerio Maggio</name><profile>https://ep2014.europython.eu//en/accounts/profile/250/</profile><image>https://ep2014.europython.eu//site_media/avatars/me_kyoto_3.jpg</image></speaker></speakers></entry><entry id="27"><category>Talk</category><audience>Novice</audience><topics><topic>Other</topic></topics><start>1500</start><duration>30</duration><room id="3">B07/B08</room><title>Python refactoring with Rope and Traad</title><description>Python is a modern, dynamic language which is growing in popularity, but tool support for it is sometime lacking or only available in specific environments. For refactoring and other common IDE functions, however, the powerful open-source rope library provides a set of tools which are designed to be integrated into almost any programming environment. Rope supports most common refactorings, such as renaming and method extraction, but also more Python-specific refactorings, such as import organization. Rope&#8217;s underlying code analysis engine also allows it to do things like locating method definitions and generating auto-completion suggestions.&#13;
&#13;
While rope is designed to be used from many environments, it&#8217;s not always easy or ideal to integrate rope directly into other programs. Traad  (Norwegian for &#8220;thread&#8221;) is another open-source project that addresses this problem by wrapping rope into a simple client-server model so that client programs (IDEs, editors, etc.) can perform refactorings without needing to embed rope directly. This simplifies dependencies, makes clients more robust in the face of errors, eases traad client development, and even allows clients to do things like switch between Python 2 and 3 refactoring in the same session.&#13;
&#13;
In this session we&#8217;ll look at how rope operates, and we&#8217;ll see how traad wraps it to provide an easier integration interface. The audience will get enough information to start using rope themselves, either directly or via traad, and they&#8217;ll see how to use traad for integrating rope into their own environments. More generally, we&#8217;ll look at why client-server refactoring tools might be preferable to the more standard approach of direct embedding. &#13;
</description><speakers><speaker id="382"><name>Austin Bingham</name><profile>https://ep2014.europython.eu//en/accounts/profile/382/</profile><image>https://ep2014.europython.eu//site_media/avatars/headshot_300x444.jpg</image></speaker></speakers></entry><entry id="97"><category>Talk</category><audience>Advanced</audience><topics><topic>Best Practices</topic></topics><start>1500</start><duration>30</duration><room id="1">C01</room><title>packaging and testing with devpi and tox</title><description>The talk discusses the following tools:&#13;
&#13;
- devpi-server for running an in-house or per-laptop python package server&#13;
&#13;
- inheritance between package indexes and from pypi.python.org public packages&#13;
&#13;
- the "devpi" client tool for uploading docs and running tests &#13;
&#13;
- running of tests through tox &#13;
&#13;
- summary view with two work flows: open source releases and in-house per-company developments &#13;
&#13;
- roadmap and in-development features of devpi and tox &#13;
&#13;
(The presenter is the main author of the tools in question). </description><speakers><speaker id="275"><name>holger krekel</name><profile>https://ep2014.europython.eu//en/accounts/profile/275/</profile><image></image></speaker></speakers></entry><entry id="39"><category>Talk</category><audience>Advanced</audience><topics><topic>System Administration</topic></topics><start>1500</start><duration>30</duration><room id="5">A08</room><title>Rethinking packaging, development and deployment</title><description>Python is often mixed with other languages in development stack, nowadays it's hard to escape any JavaScript dependencies. If you add some C dependencies such as GStreamer to the stack, packaging becomes a burden.&#13;
&#13;
While tweaking our packaging infrastructure will make things better, it's hard to fix fundamental problem of packaging with current ad-hoc solutions in Python domain.&#13;
&#13;
Using Nix (http://nixos.org/nix/) for about a year gave me an insight that solving packaging problem at operating system level (bottom-up) is a better approach.&#13;
&#13;
For example, wouldn't it be cool to have "virtualenv" implemented inside your package manager, so you could isolate also non-Python dependencies and not just Python packages for your project and not worry if system was updated?&#13;
&#13;
We'll also show what benefits do we get by using the same tool for development and deployment and how little we have to do to deploy our application.&#13;
&#13;
To see how Haskell community is touching the same subject, see blog post http://ocharles.org.uk/blog/posts/2014-02-04-how-i-develop-with-nixos.html&#13;
&#13;
</description><speakers><speaker id="182"><name>Domen Ko&#382;ar</name><profile>https://ep2014.europython.eu//en/accounts/profile/182/</profile><image>https://ep2014.europython.eu//site_media/avatars/domen.jpeg</image></speaker></speakers></entry></day><day date="2014-07-22"><entry id="33"><category>Talk</category><audience>Advanced</audience><topics><topic>Science</topic></topics><start>0900</start><duration>60</duration><room id="4">B09</room><title>Big Data Analytics with Python using Stratosphere</title><description>[Stratosphere](http://stratosphere.eu/) is implemented in Java. In 2013 we introduced support for writing Stratosphere programs in Scala. Since Scala also runs in the Java JVM the language integration was easy for Scala.&#13;
&#13;
In late 2013, we started to develop a generic language binding framework for Stratosphere to support non-JVM languages such as Python, JavaScript, Ruby but also compiled languages such as C++. The language binding framework uses [Google&#8217;s Protocol Buffers](https://code.google.com/p/protobuf/) for efficient data serialization and transportation between the languages.&#13;
&#13;
Since many &#8220;Data Scientists&#8221; and machine learning experts are using Python on a daily basis, we decided to use Python as the reference implementation for Stratosphere&#8217;s language binding feature.&#13;
Our talk at the EuroPython 2014 will present how Python developers can leverage the Stratosphere Platform to solve their big data problems.&#13;
&#13;
We introduce the most important concepts of Stratosphere such as the operators, connectors to data sources, data flows, the compiler, iterative algorithms and more.&#13;
Stratosphere is a mature, next generation big-data analytics platform developed by a vibrant [open-source community](https://github.com/stratosphere/stratosphere). The system is available under the Apache 2.0 license. &#13;
&#13;
The project started in 2009 as a joint research project of multiple universities in the Berlin area (Technische Universit&#228;t, Humboldt Universit&#228;t and Hasso-Plattner Institut). Nowadays it is an award winning system that has gained worldwide attention in both research and industry.&#13;
&#13;
A note to the program committee: As mentioned, the development of the Python language binding of Stratosphere has started a few months ago, therefore, the code is not yet in the main development branch. However, we are already able to execute the &#8220;Hello World&#8221; of big data, the &#8220;Word Count&#8221; example using the Python interface. See this example in the development branch: https://github.com/filiphaase/stratosphere/blob/langbinding/stratosphere-addons/stratosphere-language-binding/src/main/python/eu/stratosphere/language/binding/wordcountexample/WordCountPlan.py&#13;
&#13;
&#13;
Please contact us if you have any questions!</description><speakers><speaker id="190"><name>rmetzger</name><profile>https://ep2014.europython.eu//en/accounts/profile/190/</profile><image></image></speaker></speakers></entry><entry id="16"><category>Talk</category><audience>Novice</audience><topics><topic>Web</topic></topics><start>0900</start><duration>60</duration><room id="3">B07/B08</room><title>Eve - REST APIs for Humans&#8482;</title><description>Nowadays everyone has data stored somewhere and needs to expose it through a Web API, possibly a RESTful one. [Eve](http://python-eve.org) is the BSD-licensed, Flask-powered RESTful application and framework that allows to effortlessly build and deploy highly customizable, fully freatured RESTful Web Services. Eve features a robust, feature rich, REST-centered API implementation. MongoDB support comes out of the box and community-driven efforts to deliver ElasticSearch and SQLAlchemy data layers are ongoing. Eve approach is such that you only need to configure your API settings and behaviour, plug in your datasource, and you&#8217;re good to go. Features such as Pagination, Sorting, Conditional Requests, Concurrency Control, Validation, HATEOAS, JSON and XML rendering, Projections, Customisable Endpoints, Rate Limiting are all included. Advanced features such as custom Authentication and Authorisation, Custom Validation, Embedded Resource Serialisation are also easily available. In my talk I will introduce the project and its community, recount why and how it's being developed, show the source code, illustrate key concepts and show the road ahead.</description><speakers><speaker id="123"><name>Nicola Iarocci</name><profile>https://ep2014.europython.eu//en/accounts/profile/123/</profile><image>https://ep2014.europython.eu//site_media/avatars/nicola.jpg</image></speaker></speakers></entry><entry id="40"><category>Talk</category><audience>Advanced</audience><topics><topic>Other</topic></topics><start>0900</start><duration>60</duration><room id="5">A08</room><title>Elasticsearch from the bottom up</title><description>## Who I am and motivation&#13;
I work with hosted Elasticsearch and have interacted with lots of developers. We see what many struggle with.&#13;
&#13;
Some relevant theory helps a lot. What follows has already lead to many "Aha!"-moments and developers piecing things together herself.&#13;
&#13;
## The inverted index&#13;
The most important index structure is actually very simple. It is essentially a sorted dictionary of terms, with a list of postings per term.&#13;
&#13;
We show three simple sample documents and the resulting inverted index.&#13;
&#13;
## The index term&#13;
The index term is the "unit of search", and the terms we make decide how we can search.&#13;
&#13;
With the inverted index and its sorted dictionary, we can quickly search for terms given their prefix.&#13;
&#13;
## Importance of text analysis&#13;
Thus, we need to transform our search problems into string prefix problems.&#13;
&#13;
This is done with text analysis, which is the process of making of index terms. It is highly important when implementing search.&#13;
&#13;
## Building indexes&#13;
The way indexes are built must balance how compact an index is, how easily we can search in it, how fast we can index documents - and the time it takes for changes to be visible.&#13;
&#13;
Lucene, and thus Elasticsearch, builds them in segments.&#13;
&#13;
## Index segments&#13;
A Lucene index consists of index segments, i.e. immutable mini-indexes.&#13;
&#13;
A search on an index is done by doing the search on all segments and merging the results.&#13;
&#13;
Segments are immutable:&#13;
&#13;
This enables important compression techniques.&#13;
Deletes are not immediate, just a marker.&#13;
Segments are occasionally merged to larger segments. Then documents are finally deleted.&#13;
New segments are made by buffering changes in memory, and written when flushing happens. Flushes are largely caused by refreshing every second, due to real time needs.&#13;
&#13;
## Caches&#13;
Caches like filter- and field caches are managed per segment. They are essential for performance.&#13;
&#13;
Immutable segments make for simple reasoning about caches. New segments only cause partial cache invalidations.&#13;
&#13;
## Elasticsearch indexes&#13;
Much like a Lucene index is made up of many segments, an Elasticsearch index is made up of many Lucene indexes.&#13;
&#13;
Two Elasticsearch indexes with 1 shard is essentially the same as one Elasticsearch index with 2 shards.&#13;
&#13;
Search all shards and merge. Much like segments, but this time possibly across machines.&#13;
&#13;
Shard / Index routing enables various partitioning strategies. Simpler than it sounds, so one important example:&#13;
&#13;
Essential for time based data, like logs: can efficiently skip searching entire indexes - and roll out old data by deleting the entire index.&#13;
&#13;
## Common pitfalls&#13;
We must design our indexing for how we search - not the searches for how things are indexed. Be careful with wildcards and regexes.&#13;
&#13;
Since segments are immutable, deleting documents is expensive while deleting an entire index is cheap.&#13;
&#13;
Updating documents is essentially a delete and re-index. Heavy updating might cause problems.&#13;
&#13;
Have enough memory and then some. Elasticsearch is very reliant on its caches.&#13;
&#13;
## Summary&#13;
We've seen how index structures are used, and why proper text processing is essential for performant searches.&#13;
&#13;
Also, you now know what index segments are, and how they affect both indexing and searching strategies.&#13;
&#13;
## Questions</description><speakers><speaker id="504"><name>Alex Brasetvik</name><profile>https://ep2014.europython.eu//en/accounts/profile/504/</profile><image>https://ep2014.europython.eu//site_media/avatars/alex_square.png</image></speaker></speakers></entry><entry id="32"><category>Talk</category><audience>Advanced</audience><topics><topic>Best Practices</topic></topics><start>0900</start><duration>60</duration><room id="2">B05/B06</room><title>Everything You Always Wanted to Know About Memory in Python But Were Afraid to Ask</title><description>This talk will cover basics of CPython memory usage. &#13;
It will start with basics like objects and data structures representation.&#13;
Then advanced memory management aspects, such as sharing, segmentation, preallocation or caching, will be discussed. Finally, memory profiling tools will be presented. </description><speakers><speaker id="292"><name>Piotr Przymus </name><profile>https://ep2014.europython.eu//en/accounts/profile/292/</profile><image>https://ep2014.europython.eu//site_media/avatars/IMG_0360-002.JPG</image></speaker></speakers></entry><entry id="74"><category>Talk</category><audience>Novice</audience><topics><topic>Other</topic></topics><start>0900</start><duration>60</duration><room id="1">C01</room><title>I want to help! How to make your first contribution to open-source.</title><description>This talk aims to show at a high-level what is the process for contributing to most open-source projects. We will go from discovering a project to how to find the contributor guidelines, prepare your contribution for submission and what happens next. The general principles will be illustrated with an example from the speaker's first contribution to OpenStack.&#13;
&#13;
The target audience for the talk is people who have never contributed to open-source, though they would like to. Although the example will be a code contribution, the process as described applies to all kinds of contributions.</description><speakers><speaker id="377"><name>Julie</name><profile>https://ep2014.europython.eu//en/accounts/profile/377/</profile><image></image></speaker></speakers></entry><entry id="88"><category>Talk</category><audience>Advanced</audience><topics><topic>Best Practices</topic></topics><start>1000</start><duration>30</duration><room id="4">B09</room><title>Metaprogramming, from decorators to macros</title><description>This talk is a journey in the wonderful world of metaprogramming.&#13;
We start off with the meaning of metaprogramming and what it can be used for.&#13;
&#13;
Then we look at what can be done in Python, introducing function and class decorators.&#13;
When decorators are not enough anymore we move to the black magic of metaclasses, showing how we can implemement a simple Django-like model with them.&#13;
&#13;
In the bonus track we'll talk about macros, as the ultimate metaprogramming weapon, showing briefly how Lisp macros work and introducing the amazing [macropy library](https://github.com/lihaoyi/macropy).&#13;
</description><speakers><speaker id="251"><name>andrea crotti</name><profile>https://ep2014.europython.eu//en/accounts/profile/251/</profile><image>https://ep2014.europython.eu//site_media/avatars/andrea_face_1.jpg</image></speaker></speakers></entry><entry id="92"><category>Talk</category><audience>Novice</audience><topics><topic>Best Practices</topic></topics><start>1000</start><duration>30</duration><room id="2">B05/B06</room><title>Marconi - OpenStack Queuing and Notification Service</title><description>Similar to other message bus frameworks, Marconi's main goals are: performance, availability, durability, fault-tolerance and scalability.&#13;
Besides providing support for queuing and notification services through OpenStack, Marconi aims to ease the design of distributed systems and allow for asynchronous work distribution without creating yet another message broker.&#13;
This talk aims to give the audience a broad look at Marconi&#8217;s architecture, design, technologies used, development process, and discuss the issues it adresses.</description><speakers><speaker id="855"><name>ykaplan</name><profile>https://ep2014.europython.eu//en/accounts/profile/855/</profile><image></image></speaker></speakers></entry><entry id="54"><category>Talk</category><audience>Advanced</audience><topics><topic>Science</topic></topics><start>1000</start><duration>30</duration><room id="3">B07/B08</room><title>Scientific Visualization with GR</title><description>Python has long been established in software development departments of research and industry, not least because of the proliferation of libraries such as *SciPy* and *Matplotlib*. However, when processing large amounts of data, in particular in combination with GUI toolkits (*Qt*) or three-dimensional visualizations (*OpenGL*), it seems that Python as an interpretative programming language may be reaching its limits.&#13;
&#13;
---&#13;
&#13;
*Outline*&#13;
&#13;
- Introduction (1 min)&#13;
    - motivation&#13;
- GR framework (2 mins)&#13;
    - layer structure&#13;
    - output devices and capabilities&#13;
- GR3 framework (1 min)&#13;
    - layer structure&#13;
    - output capabilities (3 mins)&#13;
        - high-resolution images&#13;
        - POV-Ray scenes&#13;
        - OpenGL drawables&#13;
        - HTML5 / WebGL&#13;
- Simple 2D / 3D examples (2 min)&#13;
- Interoperability (PyQt/PySide, 3 min)&#13;
- How to speed up Python scripts (4 mins)&#13;
    - Numpy&#13;
    - Numba (Pro) &#13;
- Animated visualization examples (live demos, 6 mins)&#13;
    - physics simulations&#13;
    - surfaces / meshes&#13;
    - molecule viewer&#13;
    - MRI voxel data&#13;
- Outlook (1 min)&#13;
&#13;
*Notes*&#13;
&#13;
Links to similar talks, tutorials or presentations can be found [here][1]. Unfortunately, most of them are in German language.&#13;
&#13;
The GR framework has already been presented in a talk at PyCon DE [2012][2] and [2013][3], during a [poster session][4] at PyCon US 2013, and at [PythonCamps 2013][5] in Cologne. The slides for the PyCon.DE 2013 talk can be found [here][6].&#13;
&#13;
As part of a collaboration the GR framework has been integrated into [NICOS][7] (a network-based control system completely written in Python) as a replacement for PyQwt.&#13;
&#13;
  [1]: http://gr-framework.org/&#13;
  [2]: https://2012.de.pycon.org/programm/schedule/sessions/54&#13;
  [3]: https://2013.de.pycon.org/schedule/sessions/45/&#13;
  [4]: https://us.pycon.org/2013/schedule/presentation/158/&#13;
  [5]: http://josefheinen.de/rasberry-pi.html&#13;
  [6]: http://iffwww.iff.kfa-juelich.de/pub/doc/PyCon_DE_2013&#13;
  [7]: http://cdn.frm2.tum.de/fileadmin/stuff/services/ITServices/nicos-2.0/dirhtml/&#13;
</description><speakers><speaker id="599"><name>Josef</name><profile>https://ep2014.europython.eu//en/accounts/profile/599/</profile><image>https://ep2014.europython.eu//site_media/avatars/jh.png</image></speaker></speakers></entry><entry id="57"><category>Talk</category><audience>Novice</audience><topics><topic>Other</topic></topics><start>1000</start><duration>30</duration><room id="1">C01</room><title>Farewell and Welcome Home: Python in Two Genders</title><description>After half a lifetime "undercover as a man" I transitioned from male to female while staying involved in the Python community. This talk discusses that transition and explores how I found life in Python as a woman different from my former life as a man and the lessons about diversity I have learned.&#13;
&#13;
This talk will include a brief discussion of what being transgender means, my experiences as I came to terms with it, and the losses and gains transition entailed. Early on I made the decision to be as open as possible and to stay engaged in the Python community as I transitioned and I will discuss why I made that decision and the levels of acceptance and support I encountered.&#13;
&#13;
Transition has been wonderfully successful, but that very transition put me in a surprisingly different world. Now being part of not one, but at least 3 groups that are minorities in the Python world gave me a very different view of a community I thought I knew, and pushed me to being an activist (or trouble maker) in spite of myself. In addition to the many positives the Python community has offered me on my journey, I will discuss the experiences that have made me understand that privilege is very much alive and well in the Python world.</description><speakers><speaker id="396"><name>Naomi Ceder</name><profile>https://ep2014.europython.eu//en/accounts/profile/396/</profile><image>https://ep2014.europython.eu//site_media/avatars/Naomi_headshot2.jpg</image></speaker></speakers></entry><entry id="63"><category>Talk</category><audience>Advanced</audience><topics><topic>Other</topic></topics><start>1000</start><duration>30</duration><room id="5">A08</room><title>Scalable Realtime Architectures in Python</title><description>Increasingly we are interested in implementing highly scalable and&#13;
fault tolerant realtime architectures such as the following:&#13;
&#13;
* Realtime aggregation. This is the realtime analogue of working with&#13;
  batched map-reduce in systems like Hadoop.&#13;
&#13;
* Realtime dashboards. Continuously updated views on all your&#13;
  customers, systems, and the like, without breaking a sweat.&#13;
&#13;
* Realtime decision making. Given a set of input streams, policy on&#13;
  what you like to do, and models learned by machine learning, optimize a&#13;
  business process. One example includes autoscaling a set of servers.&#13;
&#13;
(We use realtime in the soft sense: systems that are continuously&#13;
computing on input streams of data and make a best effort to keep up;&#13;
it certainly does not imply hard realtime systems that strictly&#13;
bound their computation times.)&#13;
&#13;
Obvious tooling for such implementations include Storm (for event&#13;
processing), Kafka (for queueing), and ZooKeeper (for tracking and&#13;
configuration). Such components, written respectively in Clojure&#13;
(Storm), Scala (Kafka), and Java (ZooKeeper), provide the desired&#13;
scalability and reliability. But what may not be so obvious at first&#13;
glance is that we can work with other languages, including Python, for&#13;
the application level of such architectures. (If so inclined, you can&#13;
also try reimplementing such components in Python, but why not use&#13;
something that's been proven to be robust?)&#13;
&#13;
In fact Python is likely a better language for the app level, given&#13;
that it is concise, high level, dynamically typed, and has great&#13;
libraries. Not to mention fun to write code in! This is especially&#13;
true when we consider the types of tasks we need to write: they are&#13;
very much like the data transformations and analyses we would have&#13;
written of say a standard Unix pipeline. And no one is going to argue&#13;
that writing such a filter in say Java is fun, concise, or even&#13;
considerably faster in running time.&#13;
&#13;
So let's look at how you might solve such larger problems. Given that&#13;
it was straightforward to solve a small problem, we might approach as&#13;
follows. Simply divide up larger problems in small one. For example,&#13;
perhaps work with one customer at a time. And if failure is an ever&#13;
present reality, then simply ensure your code retries, just like you&#13;
might have re-run your pipeline against some input files.&#13;
&#13;
Unfortunately both require distributed coordination at scale. And&#13;
distributed coordination is challenging, especially for real systems,&#13;
that will break at scale. Just putting a box in your architecture&#13;
labeled **"ZooKeeper"** doesn't magically solve things, even if&#13;
ZooKeeper can be a very helpful part of an actual solution.&#13;
&#13;
Enter the Storm framework. While Storm certainly doesn't solve all&#13;
problems in this space, it can support many different types of&#13;
realtime architectures and works well with Python. In particular,&#13;
Storm solves two key problems for you.&#13;
&#13;
**Partitioning**. Storm lets you partition streams, so you can break&#13;
down the size of your problem. But if the a node running your code&#13;
fails, Storm will restart it. Storm also ensures such topology&#13;
invariants as the number of nodes (spouts and bolts in Storm's lingo)&#13;
that are running, making it very easy to recover from such failures.&#13;
&#13;
This is where the cleverness really begins. What can you do if you can&#13;
ensure that **all the data** you need for a given continuously updated&#13;
computation - what is the state of this customer's account?  - can be&#13;
put in **exactly one place**, then flow the supporting data through it&#13;
over time? We will look at how you can readily use such locality in&#13;
your own Python code.&#13;
&#13;
**Retries**. Storm tracks success and failure of events being&#13;
processed efficiently through a batching scheme and other&#13;
cleverness. Your code can then choose to retry as necessary. Although&#13;
Storm also supports exactly-once event processing semantics, we will&#13;
focus on the simpler model of at-least-once semantics. This means your&#13;
code must tolerate retry, or in a word, is idempotent. But this is&#13;
straightforward. We have often written code like the following:&#13;
&#13;
    seen = set()&#13;
    for record in stream:&#13;
        k = uniquifier(record)&#13;
        if k not in seen:&#13;
           seen.add(k)&#13;
           process(record)&#13;
&#13;
Except of course that any such real usage has to ensure it doesn't&#13;
attempt to store all observations (first, download the Internet! ;),&#13;
but removes them by implementing some sort of window or uses data&#13;
structures like HyperLogLog, as we will discuss.&#13;
&#13;
One more aspect of reliability we will discuss is how to compose&#13;
reliable systems out of reliable components; we will show how this&#13;
can be readily done with a real example of consuming Kafka and&#13;
tracking consumption progress in ZooKeeper.</description><speakers><speaker id="414"><name>Jim Baker</name><profile>https://ep2014.europython.eu//en/accounts/profile/414/</profile><image></image></speaker></speakers></entry><entry id="76"><category>Training</category><audience>Novice</audience><topics></topics><start>1000</start><duration>180</duration><room id="7">A05/A06</room><title>Einsteigertutorium Python</title><description>Das Einsteigertutorium Python wendet sich an Tagungsteilnehmer, die keine oder&#13;
nur sehr wenig Kenntnis der Programmiersprache Python besitzen. Es soll jedoch&#13;
keine Einf&#252;hrung ins Programmieren sein; praktische Erfahrung mit einer&#13;
anderen Programmiersprache wird vorausgesetzt. Am Ende der Veranstaltung&#13;
werden die Teilnehmer die syntaktischen und einige konzeptionelle Merkmale von&#13;
Python kennen und in der Lage sein, selbst&#228;ndig einfache Programme in dieser&#13;
Sprache zu erstellen und auszuf&#252;hren.&#13;
&#13;
Die Teilnehmer des Tutoriums bringen bitte ihren eigenen Rechner mit, auf dem&#13;
eine aktuelle Version von Python (mindestens 3.3) installiert sein mu&#223;. Als&#13;
Entwicklungsumgebung werden wir im Tutorium das mit Python ausgelieferte&#13;
"idle" verwenden, was je nach Betriebssystem m&#246;glicherweise zus&#228;tzliche&#13;
Bibliotheken ben&#246;tigt oder als eigenes Programmpaket installiert werden mu&#223;.&#13;
Teilnehmer, die mit der Kommandozeile und einem einfachen Texteditor vertraut&#13;
sind, k&#246;nnen auch gern diese Arbeitsumgebung verwenden. Im Tutorium wird&#13;
jedoch keine Zeit sein, um auf damit verbundene Probleme einzugehen.</description><speakers><speaker id="549"><name>Thomas Lotze</name><profile>https://ep2014.europython.eu//en/accounts/profile/549/</profile><image>https://ep2014.europython.eu//site_media/avatars/profilbild-norwegen.jpg</image></speaker></speakers></entry><entry id="67"><category>Training</category><audience>Novice</audience><topics></topics><start>1000</start><duration>180</duration><room id="6">A03/A04</room><title>Python for System Administrators</title><description>The training is an excerpt from an 8-hour course I usually do to junior and internship colleagues.&#13;
&#13;
It's goal is to show how to use python and the Python Standard Library to replace a variegate set of administration tools like grep, sed, awk, perl and gnuplot.&#13;
&#13;
Students should type-in slide contents in their ipython console and share their results. Anyway script templates are provided via github to enable them to paste snippets and reduce idle times.&#13;
&#13;
At the end of the training the students will be able to:&#13;
&#13;
- gather system data on different platforms;&#13;
- parse them efficiently;&#13;
- make basic statistics like distribution, deviation, aggregation, correlation;&#13;
- plot data;&#13;
&#13;
Bonus track (if the students finish all the slides before the end of the train):&#13;
&#13;
- use the &#160;Python Standard Library to monitor services;&#13;
- expose monitored data via http with flask;</description><speakers><speaker id="248"><name>Roberto Polli</name><profile>https://ep2014.europython.eu//en/accounts/profile/248/</profile><image>https://ep2014.europython.eu//site_media/avatars/rpolli_400.jpg</image></speaker></speakers></entry><entry id="2"><category></category><audience></audience><topics></topics><start>1030</start><duration>30</duration><room>C01, B05/B06, B07/B08, B09, A08</room><title>&#127861; Breakfast</title><description></description><speakers></speakers></entry><entry id="65"><category>Talk</category><audience>Advanced</audience><topics><topic>Science</topic></topics><start>1100</start><duration>45</duration><room id="5">A08</room><title>Performance Python for Numerical Algorithms</title><description>This talk is about several approaches to implement high performing numerical algorithms and applications in Python. It introduces into approaches like multi-threading, parallelization (CPU/GPU), dynamic compiling, high throughput IO operations.&#13;
&#13;
The approach is a practical one in that every approach is illustrated by specific Python examples.&#13;
&#13;
The talk uses, among others, the following libraries:&#13;
&#13;
* NumPy&#13;
* numexpr&#13;
* IPython.Parallel&#13;
* Numba&#13;
* NumbaPro&#13;
* PyTables</description><speakers><speaker id="730"><name>Yves</name><profile>https://ep2014.europython.eu//en/accounts/profile/730/</profile><image></image></speaker></speakers></entry><entry id="89"><category>Talk</category><audience>Advanced</audience><topics><topic>Web</topic></topics><start>1100</start><duration>45</duration><room id="3">B07/B08</room><title>The inner guts of Bitbucket</title><description>This talk is about Bitbucket's architecture. Leaving no stone unturned, I'll be covering the entire infrastructure. Every component, from web servers to message brokers and load balancing to managing hundreds of terabytes of data.&#13;
&#13;
Since its inception in 2008, Bitbucket has grown from a standard, modest Django app into a large, complex stack that while still based around Django, has expanded into many more components.&#13;
&#13;
Today Bitbucket is more than 30 times bigger than at the time of acquisition almost 4 years ago and serves Git and Mercurial repos to over a million users and growing faster now than ever before.&#13;
&#13;
Our current architecture and infrastructure was shaped by rapid growth and has resulted in a large, mostly horizontally scalable system. What has not changed is that it's still nearly all Python based and could serve as inspiration or validation for other community members responsible for rapidly scaling their apps.&#13;
&#13;
This talk will layout the entire architecture and motivate our technology choices. From our Gunicorn to Celery and HA-Proxy to NFS.&#13;
</description><speakers><speaker id="821"><name>Erik van Zijst</name><profile>https://ep2014.europython.eu//en/accounts/profile/821/</profile><image>https://ep2014.europython.eu//site_media/avatars/erik-avatar.jpg</image></speaker></speakers></entry><entry id="15"><category>Talk</category><audience>Novice</audience><topics><topic>Other</topic></topics><start>1100</start><duration>45</duration><room id="2">B05/B06</room><title>Systems Integration: The OpenStack success story</title><description>Abstract&#13;
=======&#13;
&#13;
OpenStack is a huge, open-source cloud provider. One of the main tenets of OpenStack is the (Shared Nothing Architecture) to which all modules stick very closely. In order to do that, services within OpenStack have adopted different strategies to integrate themselves and share data without sacrificing performance nor moving away from SNA.&#13;
&#13;
This strategies are not applicable just to OpenStack but to any distributed system. Sharing data, regardless what that data is, is a must-have requirement of any successful cloud service.&#13;
&#13;
This talk will present some of the existing integration strategies that are applicable to cloud infrastructures and enterprise services. The talk will be based on the strategies that have helped OpenStack to be successful and most importantly, scalable.&#13;
&#13;
Details&#13;
======&#13;
&#13;
Along the lines of what I've described in the abstract, the presentation will walk the audience through the state of the art of existing system integration solutions, the ones that have been adopted by OpenStack and the benefits of those solutions. At the end of the talk, a set of solutions under development, ideas and improvements to the existing ones will be presented.&#13;
&#13;
The presentation is oriented to distributed services, fault-tolerance and replica determinism. It's based on a software completely written in python and running successfully on several production environments.&#13;
&#13;
The presentation will be split in 3 main topics:&#13;
&#13;
Distributed System integration&#13;
-----------------------------------&#13;
&#13;
* What's it ?&#13;
* Why is it essential for cloud infrastructures?&#13;
* Existing methods and strategies&#13;
&#13;
OpenStack success story&#13;
----------------------------&#13;
&#13;
* Which methods did OpenStack adopt?&#13;
* How / Why do they work?&#13;
* What else could be done?&#13;
&#13;
Coming Next&#13;
---------------&#13;
&#13;
* Some issues of existing solutions&#13;
* What are we doing to improve that?&#13;
* Other solutions coming up</description><speakers><speaker id="54"><name>Flavio Percoco</name><profile>https://ep2014.europython.eu//en/accounts/profile/54/</profile><image>https://ep2014.europython.eu//site_media/avatars/Screen-Shot-2013-09-12-at-8.40.46-AM.png</image></speaker></speakers></entry><entry id="60"><category>Talk</category><audience>Novice</audience><topics><topic>Education</topic></topics><start>1100</start><duration>45</duration><room id="4">B09</room><title>Python for Zombies: 15.000 enrolled in the first Brazilian MOOC to teach Python</title><description>Python for Zombies is the first free MOOC (Massive Open Online Course) to teach programming with Python in Brazil. Our first edition had 15.000 "zombies".  This course is very different from traditional MOOCs (Edx, Coursera, etc.). Besides the difference of language, it is very "casual", as I have little time, I recorded most of the videos on my trips between meetings, conferences or at mealtimes. This MOOC is "brazilian", in a non traditional academic way. The size of the videos is far lower than the average traditional courses too. I'm recording the Spanish version! I will show you the most funny codes that I used in MOOC classes to teach programming:  hacking basic modules and classes to obtain the "Answer to the Ultimate Question of Life, the Universe, and Everything". All material is Creative Commons Share Alike. The MOOC is based in my experience to teach programming in past six years at FATEC, a public university in Brazil, with decreasing rates of failure in the introduction to programming discipline. We have 100% class in labs, Coding Dojos to training and tests in exercises. Slides for this same title in a talk I give in PyCon Uruguay 2013: http://www.slideshare.net/fmasanori/python-for-zombies-first-brazilian-programming-mooc Important observation: these slides that I used in the PyConUy will be going to be totally translated into English.</description><speakers><speaker id="46"><name>Fernando Masanori Ashikaga</name><profile>https://ep2014.europython.eu//en/accounts/profile/46/</profile><image>https://ep2014.europython.eu//site_media/avatars/Masanori_winter.jpg</image></speaker></speakers></entry><entry id="48"><category>Talk</category><audience>Advanced</audience><topics><topic>Other</topic></topics><start>1100</start><duration>45</duration><room id="1">C01</room><title>Out-of-Core Columnar Datasets</title><description>It is a fact: we just entered in the Big Data era.  More sensors, more&#13;
computers, and being more evenly distributed throughout space and time&#13;
than ever, are forcing data analyists to navigate through oceans of&#13;
data before getting insights on what this data means.&#13;
&#13;
Tables are a very handy and spreadly used data structure to store&#13;
datasets so as to perform data analysis (filters, groupings, sortings,&#13;
alignments...).  However, the actual table implementation, and&#13;
especially, whether data in tables is stored row-wise or column-wise,&#13;
whether the data is chunked or sequential, whether data is compressed or not,&#13;
among other factors, can make a lot of difference depending on the&#13;
analytic operations to be done.&#13;
&#13;
My talk will provide an overview of different libraries/systems in the&#13;
Python ecosystem that are designed to cope with tabular data, and how&#13;
the different implementations perform for different operations.  The&#13;
libraries or systems discussed are designed to operate either with&#13;
on-disk data ([PyTables] [1], [relational databases] [2], [BLZ] [3],&#13;
[Blaze] [4]...) as well as in-memory data containers ([NumPy] [5],&#13;
[DyND] [6], [Pandas] [7], [BLZ] [3], [Blaze] [4]...).&#13;
&#13;
A special emphasis will be put in the on-disk (also called&#13;
out-of-core) databases, which are the most commonly used ones for&#13;
handling extremely large tables.&#13;
&#13;
The hope is that, after this lecture, the audience will get a better&#13;
insight and a more informed opinion on the different solutions for&#13;
handling tabular data in the Python world, and most especially, which&#13;
ones adapts better to their needs.&#13;
&#13;
[1]: http://www.pytables.org&#13;
[2]: http://en.wikipedia.org/wiki/Relational_database&#13;
[3]: http://blz.pydata.org&#13;
[4]: http://blaze.pydata.org&#13;
[5]: http://www.numpy.org/&#13;
[6]: https://github.com/ContinuumIO/dynd-python&#13;
[7]: http://pandas.pydata.org/&#13;
</description><speakers><speaker id="695"><name>Francesc Alted</name><profile>https://ep2014.europython.eu//en/accounts/profile/695/</profile><image>https://ep2014.europython.eu//site_media/avatars/foto-meua.png</image></speaker></speakers></entry><entry id="68"><category>Talk</category><audience>Advanced</audience><topics><topic>System Administration</topic></topics><start>1145</start><duration>45</duration><room id="3">B07/B08</room><title>Packaging in packaging: dh-virtualenv</title><description>[Dh-virtualenv][1] is an open source tool developed at Spotify. We use it&#13;
to ease deploying our Python software to production. We built dh-virtualenv as a tool that fits our existing continuous integration flow with a dedicated sbuild server.&#13;
As we were already packaging software in Debian packages, the&#13;
aim of dh-virtualenv was to make transition to virtualenv based installations as smooth as possible.&#13;
&#13;
This talk covers how you can use dh-virtualenv to help you deploy your&#13;
software to production, where you are already running a Debian-based system, such as Ubuntu, and what are the advantages and disadvantages of the approach over other existing and&#13;
popular techniques. We will discuss the deploying as a problem in&#13;
general, look into building a dh-vritualenv-backed package, and in the&#13;
end, look into how dh-virtualenv was actually made.&#13;
&#13;
Goal is that after this presentation you know how to make your Debian/Ubuntu deployments easier!&#13;
&#13;
[dh-virtualenv][1] if fully open sourced, production tested software,&#13;
licensed under GPLv2+ and available in Debian testing and unstable.&#13;
&#13;
More information of it is also available in our [blogpost][2].&#13;
&#13;
&#13;
Talk outline:&#13;
&#13;
1. Introduction &amp; overview (3min)&#13;
    * Who am I?&#13;
    * Why am I fiddling with Python packaging?&#13;
    * What do you get out of this talk?&#13;
2.  Different shortcomings of Python deployments (5min)&#13;
    * Native system packages&#13;
    * Virtualenv based installations&#13;
    * Containers, virtual machine images&#13;
3. dh-virtualenv (10 min)&#13;
    * What is dh-virtualenv?&#13;
    * Thought behind dh-virtualenv&#13;
    * Advantages over others&#13;
    * Requirements for your deployment flow&#13;
    * Short intro to packaging Sentry with dh-virtualenv&#13;
4. How is it built? (10 min)&#13;
    * Debian package building flow primer&#13;
    * How dh-virtualenv fits that flow&#13;
    * What does it do build time and why?&#13;
&#13;
[1]:http://github.com/spotify/dh-virtualenv&#13;
[2]:http://labs.spotify.com/2013/10/10/packaging-in-your-packaging-dh-virtualenv/&#13;
</description><speakers><speaker id="733"><name>Jyrki Pulliainen</name><profile>https://ep2014.europython.eu//en/accounts/profile/733/</profile><image>https://ep2014.europython.eu//site_media/avatars/jyrki.jpg</image></speaker></speakers></entry><entry id="34"><category>Talk</category><audience>Advanced</audience><topics><topic>Other</topic></topics><start>1145</start><duration>45</duration><room id="5">A08</room><title>Embedding Python: Charming the Snake with C++</title><description>Python with its huge standard library and sophisticated packages developed by its thriving community has become an incredibly useful tool for data scientists. At Blue Yonder, we value Python for the ease with which we can access and combine machine learning algorithms to build accurate prediction models.&#13;
&#13;
To get the most business value out of the use of Python, we strive to rid our model developers from all burdens outside their core expertise, i.e., developing statistical models. To leverage our existing infrastructure, essentially a distributed scheduling system written in C++, we decided to embed a Python interpreter in our application. The goal was to let developers use the language best suited for their problem, and to let them incorporate code created by others even if it is not written in the same language.&#13;
&#13;
In this presentation, I will talk about a few obstacles which we had to overcome in integrating the (C)Python interpreter in our C++ program, e.g., clean resource management, error handling, and broken features in the interpreter's API. I will show how we employed features from the Boost Python C++ library [1] not only for simple data exchange, but also for more powerful concepts such as data sources. Finally, I will demonstrate how C++ objects can be used to seamlessly interact with Python, for example to use Python's logging package as usual while the actual logging is handled by our C++ application.&#13;
&#13;
With this combination of both worlds, we achieved a desirable mix of virtues: safe, reliable operations; good run-time performance; fast development; and highly expressive, unit testable core domain logic.&#13;
&#13;
[1]: See http://www.boost.org/doc/libs/1_55_0/libs/python/</description><speakers><speaker id="410"><name>Michael K&#246;nig</name><profile>https://ep2014.europython.eu//en/accounts/profile/410/</profile><image>https://ep2014.europython.eu//site_media/avatars/20130424_BlueYonder_151.jpg</image></speaker></speakers></entry><entry id="37"><category>Talk</category><audience>Novice</audience><topics><topic>Best Practices</topic></topics><start>1145</start><duration>45</duration><room id="1">C01</room><title>How to Setup a new Python Project</title><description>Whenever a Python beginner starts with its own project he or she is confronted with the same technical questions. Questions about a well thought out directory structure to hold all the files. How setup.py needs to be configured and even what it is capable of like specifying entry_points and other goodies. We show from the experience of our yearslong work with Python how to structure your Python project in terms of folders, files, modules and packages. How to configure setup.py to specify your requirements, to use it with nosetests, with Sphinx and so on. We also elaborate on the usage of Git and Versioneer (https://github.com/warner/python-versioneer) to help you version your package.</description><speakers><speaker id="430"><name>Felix Wick</name><profile>https://ep2014.europython.eu//en/accounts/profile/430/</profile><image>https://ep2014.europython.eu//site_media/avatars/felix1.jpg</image></speaker><speaker id="375"><name>Florian Wilhelm</name><profile>https://ep2014.europython.eu//en/accounts/profile/375/</profile><image></image></speaker></speakers></entry><entry id="35"><category>Talk</category><audience>Novice</audience><topics><topic>Other</topic></topics><start>1145</start><duration>45</duration><room id="4">B09</room><title>Writing Awesome Command-Line Programs in Python</title><description>Python is a great language for writing command-line tools - which is why so much of Linux is secretly written in Python these days. Unfortunately, what starts as a simple script can quickly get out of hand as more features are added and more people start using it!&#13;
&#13;
The talk will consist of a tour through various useful libraries and practical code showing how each can be used, and include advice on how to best structure simple and complex command-line tools.&#13;
&#13;
Things to consider when writing command-line apps:&#13;
&#13;
* Single-file vs Multiple-file&#13;
* Standard library only vs. 3rd party requirements&#13;
* Installation - setup.py vs. native packaging&#13;
&#13;
The different parts of a command-line program:&#13;
&#13;
* Option Parsing:&#13;
    * Libraries: getopt, optparse, argparse, docopt&#13;
    * Sub-commands&#13;
* Configuration:&#13;
    * Formats: Ini file, JSON, YAML&#13;
    * Where should it be stored (cross-platform);&#13;
    * Having multiple configuration files, and allowing user config to override global config&#13;
* Output:&#13;
    * Colour - colorama&#13;
    * Formatting output for the user&#13;
    * Formatting output for other programs&#13;
    * How do you know when your output is being piped to another program?&#13;
    * Managing logging and verbosity&#13;
* Managing streamed input&#13;
* Exit values: What are the conventions?&#13;
* Interactive apps - REPL&#13;
* Structuring a bunch of programs/commands around a shared codebase.&#13;
* Command-line frameworks: clint, compago &amp; cliff&#13;
* Testing command-line apps&#13;
* Writing command-line tools in Python 3 vs Python 2</description><speakers><speaker id="423"><name>Mark Smith</name><profile>https://ep2014.europython.eu//en/accounts/profile/423/</profile><image>https://ep2014.europython.eu//site_media/avatars/512.png</image></speaker></speakers></entry><entry id="66"><category>Talk</category><audience>Novice</audience><topics><topic>Science</topic></topics><start>1145</start><duration>45</duration><room id="2">B05/B06</room><title>Combining the powerful worlds of Python and R</title><description>pyRserve is a small open source project originally developed to fulfill the needs of a German biotech company to do statistical analysis in a large Python-based Lab Information Management System (LIMS). In contrast to other R-related libraries like RPy where Python and R run on the same host, pyRserve allows the distribution of complex operations and calculations over multiple R servers across the network. &#13;
&#13;
The aim of this talk is to show how easily Python can be connected to R, and to present a number of selected (simple) code examples which demonstrate the power of this setup.</description><speakers><speaker id="686"><name>Ralph Heinkel</name><profile>https://ep2014.europython.eu//en/accounts/profile/686/</profile><image>https://ep2014.europython.eu//site_media/avatars/ralph-no-panic.jpg</image></speaker></speakers></entry><entry id="5"><category></category><audience></audience><topics></topics><start>1230</start><duration>90</duration><room>C01, B05/B06, B07/B08, B09, A08</room><title>&#127860; Lunch</title><description></description><speakers></speakers></entry><entry id="20"><category>Talk</category><audience>Advanced</audience><topics><topic>Web</topic></topics><start>1400</start><duration>30</duration><room id="2">B05/B06</room><title>Morepath: a Python Web Framework with Super Powers</title><description>[Morepath](http://morepath.readthedocs.org) is a new server web&#13;
framework written with modern, rich client web development in mind.&#13;
&#13;
In the talk I will be discussing some core features of Morepath that&#13;
make it different:&#13;
&#13;
* Its different take on routing and linking. Morepath has support&#13;
  to help you construct hyperlinks to models.&#13;
* Its view system: plain views, generic views, view composition.&#13;
* Morepath's approach to application construction allows application extension and overriding, and composition.&#13;
&#13;
This talk will attempt to convince people to try Morepath. For those&#13;
unable or unwilling to try, I will communicate some design principles&#13;
behind Morepath which can be of help to any web developer.</description><speakers><speaker id="284"><name>Martijn Faassen</name><profile>https://ep2014.europython.eu//en/accounts/profile/284/</profile><image></image></speaker></speakers></entry><entry id="30"><category>Talk</category><audience>Advanced</audience><topics><topic>Other</topic></topics><start>1400</start><duration>30</duration><room id="4">B09</room><title>The Return of "The Return of Peer to Peer Computing".</title><description>This talk introduces, describes and demonstrates concepts and code created during sprints and via online collaboration by a distributed group of Pythonistas under the working title p4p2p (http://p4p2p.net).&#13;
&#13;
We asked ourselves, as frameworks such as Zope/Plone, Django, Pyramid or Flask are to web development what would the equivalent sort of framework look like for peer-to-peer application development?&#13;
&#13;
We've tackled several different technical issues: remote execution of code among peers, distributed hash tables as a mechanism for peer discovery and data storage, various cryptographic requirements and the nuts and bolts of punching holes in firewalls.&#13;
&#13;
Work is ongoing (we have another sprint at the end of March) and the final content of the talk will depend on progress made. However, we expect to touch upon the following (subject to the caveat above):&#13;
&#13;
* What is the problem we're trying to solve?&#13;
* Why P2P?&#13;
* The story of how we ended up asking the questions outlined in the abstract.&#13;
* What we've done to address these questions.&#13;
* An exploration of the sorts of application that could be built using P2P.&#13;
* A call for helpers and collaboration.&#13;
&#13;
Happy to answer any questions!</description><speakers><speaker id="58"><name>Nicholas Tollervey</name><profile>https://ep2014.europython.eu//en/accounts/profile/58/</profile><image>https://ep2014.europython.eu//site_media/avatars/lookslikeme.JPG</image></speaker><speaker id="275"><name>holger krekel</name><profile>https://ep2014.europython.eu//en/accounts/profile/275/</profile><image></image></speaker></speakers></entry><entry id="29"><category>Talk</category><audience>Advanced</audience><topics><topic>System Administration</topic></topics><start>1400</start><duration>30</duration><room id="1">C01</room><title>Deploying and managing FreeBSD jails with mr.awsome, fabric and ansible</title><description>FreeBSD jails provide a light-weight but powerful and secure way to virtualise services. However, the *BSD world has sort of stood on the side lines as the recent advances in systems deployment have developed. I.e. while vagrant, puppet, chef, ansible etc. have gained a great deal of acceptance in the Linux world, they often only consider BSD as an afterthought, which is a shame.&#13;
&#13;
Well, mr.awsome has changed this! With its declarative provisioning approach you simply define a jail host and its jails and mr.awsome will go about and make it so.&#13;
&#13;
Configuring a jail then simply becomes a matter of applying one or more ansible playbooks to it and maintenance operations such as performing updates, backups, managing services etc. that don't quite fit the declarative approach of ansible can then easily be applied using Fabric - all powered by a single, canonical configuration!&#13;
&#13;
By separating provisioning from declarative and imperative configuration each area becomes much more concise and clean.&#13;
&#13;
Having great Python tools for each of these areas allows mr.awsome to tie them together on API level to provide a seemless, powerful solution that becomes greater than the sum of its parts.&#13;
&#13;
</description><speakers><speaker id="387"><name>tomster</name><profile>https://ep2014.europython.eu//en/accounts/profile/387/</profile><image></image></speaker></speakers></entry><entry id="8"><category>Talk</category><audience>Novice</audience><topics><topic>System Administration</topic></topics><start>1400</start><duration>30</duration><room id="3">B07/B08</room><title>For lack of a better name(server): DNS Explained</title><description>Following instructions of what entries to create where is easy enough when using a PaaS.&#13;
&#13;
But DNS is hard &#8211; deployment issues always seem to come down to DNS.&#13;
&#13;
A solid understanding of DNS will not only help with deploying your applications, but will also give a greater understanding of how the internet works, and more generally, distributed systems.&#13;
&#13;
In this talk, you will learn what DNS is, how it works and how to communicate with it, and how Python can make both interacting and spinning up your own DNS server simple (I swear!).  &#13;
&#13;
Outline:&#13;
&#13;
* Intro (1-2m)&#13;
* What DNS is (5 min)&#13;
    * URL -&gt; IP addr, e.g. "phonebook" lookup (obligatory pun: Call me, Maybe?)&#13;
    * hierarchical system &amp; resolution sequence (local DNS cache/resolver, ISP resolver, recursive DNS search)&#13;
    * popular types (primary, secondary/slave, forwarding, authoritative only, etc)&#13;
    * System components: what makes a DNS?&#13;
* How to communicate with DNS (3 min)&#13;
    * Protocol: UDP&#13;
    * Operations: CRUD&#13;
    * Resource records (A, AAAA, CNAME, SOA, SRV, etc)&#13;
    * tools: dig/nsupdate/nslookup&#13;
* Security overview (3min) (disclaimer: NOT a DNS security expert, not planning to get into the details here)&#13;
    * Server-Server, DynDNS: TSIG/GSS-TSIG&#13;
    * Server-Client: DNSSEC&#13;
* Python + DNS (10 min)&#13;
    * plain UDP query in Python (no 3rd-party libraries/no magic)&#13;
    * Interacting with a DNS w/ Python (dnspython.py)&#13;
    * Sample DNS server with Twisted&#13;
    * "fake" demo (either local or pre-recorded screen cast) of querying/updating/etc of the Twisted DNS&#13;
* Wrap up - resources page, github links, etc (1min)&#13;
* Q&amp;A - ~5 min </description><speakers><speaker id="212"><name>Lynn Root</name><profile>https://ep2014.europython.eu//en/accounts/profile/212/</profile><image>https://ep2014.europython.eu//site_media/avatars/2013-09-30_at_3.31_PM.png</image></speaker></speakers></entry><entry id="9"><category>Talk</category><audience>Advanced</audience><topics><topic>Other</topic></topics><start>1400</start><duration>30</duration><room id="5">A08</room><title>How Pony ORM translates Python generators to SQL queries</title><description>[Pony ORM](http://ponyorm.com) is an object-relational mapper implemented in Python. It allows writing advanced queries to a database using plain Python in the form of a generator expression. This way queries look very concise.&#13;
&#13;
The main feature of Pony is to provide a method to write declarative queries to databases in pure Python using generators. For this purpose Pony analyzes the abstract syntax tree of a generator and translates it to its SQL equivalent.&#13;
&#13;
Following is a sample of a query in Pony:&#13;
&#13;
    select(p for p in Product if "iPad" in p.name and p.price &gt;= 500)&#13;
&#13;
This query translates to SQL using a specific database dialect. Currently Pony works with SQLite, MySQL, PostgreSQL and Oracle databases.&#13;
&#13;
In this talk one of Pony ORM authors will go through the process of the query translation and dig into the implementation details.&#13;
&#13;
Attendees are going to walk away with the understanding of: &#13;
&#13;
1. Principles of building a programming language translator&#13;
2. Python to SQL translator implementation details &#13;
3. Approaches for creating a pluggable translator architecture &#13;
&#13;
The presentation outline:&#13;
&#13;
- Why Python generators are good for representing SQL queries&#13;
- Main stages of Python to SQL translation overview&#13;
- Decompiling Python bytecode into Python AST&#13;
- Translating Python AST to database-independent SQL representation&#13;
- Generating SQL for specific database&#13;
- Pluggable translator architecture&#13;
- Performance concerns: is such way of building SQL slower or faster then Django's and SQLAlchemy's?</description><speakers><speaker id="229"><name>Alexey Malashkevich</name><profile>https://ep2014.europython.eu//en/accounts/profile/229/</profile><image>https://ep2014.europython.eu//site_media/avatars/eu_ava.jpg</image></speaker></speakers></entry><entry id="18"><category>Training</category><audience>Novice</audience><topics></topics><start>1400</start><duration>180</duration><room id="7">A05/A06</room><title>PySide - Develop System GUI</title><description>Well, when it comes to GUI programming, it is always considered to be hectic at least for the early language developers like C, C++.  Its because of the 100 lines of code that you end up writing to just create a button object. There comes a rescue for this, the GUI programming is made a little easier with the introduction of tool kits such as Tcl/Tk, Qt, wxwidgets etc. These libraries made our life a lot simpler by providing the wrapper framework in the native language.&#13;
 &#13;
One such framework developed for Python by Qt is PySide. It is a cross-platform UI framework, meaning that you can run the same code in almost any operating systems, say, for example, Linux, Unix, Windows, Macintosh etc with no or little changes to the code. The best part of PySide is its licensing. PySide has been published as a response to the lack of suitably licensed Qt bindings for Python. PySide is licensed under the LGPL version 2.1 license, allowing both Free/Open source software and proprietary software development. The python wiki page gives more info about the various other GUI frameworks used by python segregated by their capabilities.&#13;
&#13;
&#13;
</description><speakers><speaker id="271"><name>Venkateshwaran Loganathan</name><profile>https://ep2014.europython.eu//en/accounts/profile/271/</profile><image></image></speaker></speakers></entry><entry id="41"><category>Training</category><audience>Advanced</audience><topics></topics><start>1400</start><duration>180</duration><room id="6">A03/A04</room><title>Developing for OpenStack in Python</title><description>If you want to program the cloud, you've come to the right place.  Here, you'll start by firing up your own fully functional OpenStack installation, go on to write no less than two Python applications for it, and end the session learning how to hack the cloud itself.  Sounds like a lot?  That's because it is!&#13;
&#13;
The training is targetted at people with Python programming experience and at least some familiarity with Linux system administration.  If you lack one (or both!) you're welcome to attend, but be forewarned that the session's time constraints leave little leeway for catching up if you fall behind.  No prior knowledge of OpenStack is required, though.&#13;
&#13;
Adolfo Brandes will be your trainer.  Adolfo started out developing an Asterisk-based PBX for large call centers, but has since worked on several websites, the odd Linux kernel driver, an AGPL3 Python-backed web game, on OpenStack contribution mentoring, and most recently, on high-availability and high-scalability with the consulting company hastexo.</description><speakers><speaker id="427"><name>Adolfo Brandes</name><profile>https://ep2014.europython.eu//en/accounts/profile/427/</profile><image>https://ep2014.europython.eu//site_media/avatars/avatar15_cropped_2.jpg</image></speaker></speakers></entry><entry id="93"><category>Talk</category><audience>Advanced</audience><topics><topic>Python Core</topic></topics><start>1430</start><duration>30</duration><room id="3">B07/B08</room><title>Advanced Database Programming with Python</title><description>The Python DB-API 2.0 provides a direct interface to&#13;
many popular database backends. It makes interaction with&#13;
relational database very straight forward and allows tapping&#13;
into the full set of features these databases provide.&#13;
&#13;
The talk will cover advanced database topics which are&#13;
relevant in production environments such as locks, distributed&#13;
transactions and transaction isolation.&#13;
&#13;
----&#13;
&#13;
The talk will give an in-depth discussion of advanced database&#13;
programming topics based on the Python DB-API 2.0: locks and&#13;
dead-locks, two-phase commits, transaction isolation, result&#13;
set scrolling, schema introspection and handling&#13;
multiple result sets.&#13;
&#13;
Talks slides are available on request.</description><speakers><speaker id="135"><name>Marc-Andre Lemburg</name><profile>https://ep2014.europython.eu//en/accounts/profile/135/</profile><image></image></speaker></speakers></entry><entry id="21"><category>Talk</category><audience>Novice</audience><topics><topic>Web</topic></topics><start>1430</start><duration>30</duration><room id="5">A08</room><title>Web Scraping in Python 101</title><description>Who am I ?&#13;
=========&#13;
* a programmer&#13;
* a high school student&#13;
* a blogger&#13;
* Pythonista&#13;
* and tea lover&#13;
- Creator of freepythontips.wordpress.com&#13;
- I made soundcloud-dl.appspot.com&#13;
- I am a main contributor of youtube-dl.&#13;
- I teach programming at my school to my friends.&#13;
- It's my first programming  related conference.&#13;
- The life of a python programmer in Pakistan&#13;
&#13;
What this talk is about ?&#13;
==================&#13;
- What is Web Scraping  and its usefulness&#13;
- Which libraries are available for the job&#13;
- Open Source vs proprietary alternatives&#13;
- Whaich library is best for which job&#13;
- When and when not to use Scrapy&#13;
&#13;
What is Web Scraping ?&#13;
==================&#13;
Web scraping (web harvesting or web data extraction) is a &#13;
computer software technique of extracting information from &#13;
websites.  - Wikipedia&#13;
&#13;
###In simple words :&#13;
It is a method to extract data from a website that does not &#13;
have an API or we want to extract a LOT of data which we &#13;
can not do through an API due to rate limiting.&#13;
&#13;
We can extract any data through web scraping which we can &#13;
see while browsing the web.&#13;
&#13;
Usage of web scraping in real life.&#13;
============================&#13;
- to extract product information&#13;
- to extract job postings and internships&#13;
- extract offers and discounts from deal-of-the-day websites&#13;
- Crawl forums and social websites&#13;
- Extract data to make a search engine&#13;
- Gathering weather data etc&#13;
&#13;
Advantages of Web scraping over using an API &#13;
========================&#13;
- Web Scraping is not rate limited&#13;
- Anonymously access the website and gather data&#13;
- Some websites do not have an API&#13;
- Some data is not accessible through an API etc&#13;
&#13;
Which libraries are available for the job ?&#13;
================================&#13;
There are numerous libraries available for web scraping in &#13;
python. Each library has its own weaknesses and plus points.&#13;
&#13;
Some of the most widely known libraries used for web scraping are:&#13;
&#13;
- BeautifulSoup&#13;
- html5lib&#13;
- lxml&#13;
- re ( not really for web scraping, I will explain later )&#13;
- scrapy ( a complete framework )&#13;
&#13;
A comparison between these libraries&#13;
==============================&#13;
- speed&#13;
- ease of use&#13;
- what do i prefer&#13;
- which library is best for which purpose&#13;
&#13;
Proprietary alternatives&#13;
==================&#13;
- a list of proprietary scrapers&#13;
- their price&#13;
- are they really useful for you ?&#13;
&#13;
Working of proprietary alternatives&#13;
===========================&#13;
- how they work (render javascript)&#13;
- why they are not suitable for you&#13;
- how custom scrapers beat proprietary alternatives&#13;
&#13;
Scrapy&#13;
=======&#13;
- what is it&#13;
- why is it useful&#13;
- asynchronous support&#13;
- an example scraper&#13;
&#13;
Question&#13;
=======&#13;
- Questions from the viewers</description><speakers><speaker id="293"><name>M.Yasoob Khalid</name><profile>https://ep2014.europython.eu//en/accounts/profile/293/</profile><image>https://ep2014.europython.eu//site_media/avatars/1150976_10201890200686592_362943838_n.jpg</image></speaker></speakers></entry><entry id="44"><category>Talk</category><audience>Novice</audience><topics><topic>Web</topic></topics><start>1430</start><duration>30</duration><room id="1">C01</room><title>Full Stack Python</title><description>This talk distills information from the open source guide [Full Stack Python](http://www.fullstackpython.com/) I wrote into a 30 minute talk on web stack layers. An approximate timeline for this talk would be:&#13;
&#13;
* 5 min: intro story&#13;
* 5 min: what the web developers need to know about virtual servers, web servers, and WSGI servers&#13;
* 5 min: what do web frameworks provide?&#13;
* 5 min: what are the most important parts of your web application to analyze and monitor?&#13;
* 5 min: static files and execution on the user's browser&#13;
* 5 min: concluding story and resources to learn more&#13;
&#13;
This is a high level overview intended for developers who are new to Python web development and need to understand what the web stack layers are and how they fit together.</description><speakers><speaker id="671"><name>Matt</name><profile>https://ep2014.europython.eu//en/accounts/profile/671/</profile><image>https://ep2014.europython.eu//site_media/avatars/matt-makai.jpg</image></speaker></speakers></entry><entry id="71"><category>Talk</category><audience>Novice</audience><topics><topic>Education</topic></topics><start>1430</start><duration>30</duration><room id="2">B05/B06</room><title>Python Generators from Scratch</title><description>The talk starts from iterators and iterables, showing the differences and the relations between the two concepts, and describing the loop protocol of the Python language. &#13;
&#13;
Here I want to introduce the concept of sequence types and a very quick mention to the innate polymorphism of Python functions due to the dynamic typing system.&#13;
&#13;
Next topic will be the yield keyword and generator objects. The generator behaviour is presented in depth, being this the most important concept of the whole topic.&#13;
&#13;
If there is enough time I would also introduce an advanced use of generators, i.e. microthreads.&#13;
&#13;
(The talk structure is that of this series of three posts http://lgiordani.github.io/blog/2013/03/25/python-generators-from-iterators-to-cooperative-multitasking/)</description><speakers><speaker id="734"><name>Leonardo Giordani</name><profile>https://ep2014.europython.eu//en/accounts/profile/734/</profile><image>https://ep2014.europython.eu//site_media/avatars/IMG_20140225_131758_1x1.jpg</image></speaker></speakers></entry><entry id="87"><category>Talk</category><audience>Advanced</audience><topics><topic>Other</topic></topics><start>1430</start><duration>30</duration><room id="4">B09</room><title>Identifying Bugs Before Runtime With Jedi</title><description>Jedi ([https://github.com/davidhalter/jedi][1]) is an autocompletion library for Python that has gained quite a following over the last year. There are a couple of plugins for the most popular editors (VIM, Sublime, Emacs, etc.) and mainstream IDEs like Spyder are switching to Jedi.&#13;
&#13;
Jedi basically tries to redefine the boundaries of autocompletion in dynamic languages. Most people still think that there's no hope for decent autocompletion in Python. This talk will try to argue the opposite, that decent autocompletion is very close.&#13;
&#13;
While the first part will be about Jedi, the second part of this talk will discuss the future of dynamic analysis. Dynamic Analysis is what I call the parts that static analysis doesn't cover. The hope is to generate a kind of "compiler" that doesn't execute code but reports additional bugs in your code (AttributeErrors and the like). &#13;
&#13;
I still have to work out the details of the presentation. I also have to add that Jedi I'm currently working full-time on Jedi and that there's going to be some major improvements until the conference. Autocompletion and static/dynamic analysis as well as refactoring are hugely important tools for a dynamic language IMHO, because they can improve the only big disadvantage compared to static languages: Finding bugs before running your tool.&#13;
&#13;
BTW: I could also do a long talk if requested, to also discuss static analysis and refactoring in depth.&#13;
&#13;
[1]: https://github.com/davidhalter/jedi</description><speakers><speaker id="746"><name>Dave Halter</name><profile>https://ep2014.europython.eu//en/accounts/profile/746/</profile><image>https://ep2014.europython.eu//site_media/avatars/guitar.jpg</image></speaker></speakers></entry><entry id="19"><category>Talk</category><audience>Advanced</audience><topics><topic>Testing</topic></topics><start>1500</start><duration>30</duration><room id="3">B07/B08</room><title>Design Your Tests</title><description>* Life span of a test&#13;
    * 5 minute - why does this fail?&#13;
    * 5 day - what is this missing?&#13;
    * 5 week - do I have coverage for this?&#13;
    * 5 month - what's *not* causing this bug?&#13;
&#13;
* Transparent simplicity&#13;
    * one or two "iceberg" layers for meaning&#13;
        * Higher-order assertions - build collections of state that have meaning for the domain in the tests&#13;
        * bulk of the details are in the code itself&#13;
&#13;
        * show an example&#13;
&#13;
    * grouping for organization&#13;
        * Mixins&#13;
&#13;
        * show an example&#13;
&#13;
* unittest issues&#13;
    * assertion/mixin clutter&#13;
    * setUp/tearDown tie grouping to the class layer or to inheritance via super&#13;
        * addCleanup&#13;
    * weak association / lookup-ability between code and its tests&#13;
        * package layout&#13;
        * other conventions&#13;
&#13;
* Alternative approaches&#13;
    * testtools' matchers&#13;
    * py.test `assert` magic</description><speakers><speaker id="204"><name>Julian Berman</name><profile>https://ep2014.europython.eu//en/accounts/profile/204/</profile><image></image></speaker></speakers></entry><entry id="23"><category>Talk</category><audience>Novice</audience><topics><topic>Testing</topic></topics><start>1500</start><duration>30</duration><room id="5">A08</room><title>Python in system testing</title><description>When you think about Python+testing, you usually think about testing your code - unittests, mostly. But it is not the only case! When you have a big system, you need to test it on much higher level - if only to check if all the components are wired in the right way. You may do it manually, but it is tedious and time-consuming - so you want to automate it. And here comes Python - the language of choice in many QA departments.&#13;
&#13;
I will tell about differences between unittesting and system testing which result in totally different requirements on test management/running systems. I will tell how we use Python (and a little why) to automate our work. Finally, I will tell a little about my "idee fixe" - a framework for system testing written in Python.</description><speakers><speaker id="314"><name>Katarzyna Jachim</name><profile>https://ep2014.europython.eu//en/accounts/profile/314/</profile><image>https://ep2014.europython.eu//site_media/avatars/kasiazt_640x427_1.jpg</image></speaker></speakers></entry><entry id="90"><category>Talk</category><audience>Advanced</audience><topics><topic>Python Core</topic></topics><start>1500</start><duration>30</duration><room id="2">B05/B06</room><title>Tweaking libraries as a step towards secure programming</title><description>During the talk we will describe techniques and architectural approaches to better control and monitor the security of a Python application handling traffic from any kind of data sources and how to restructure the code to better handle the unexpected. &#13;
&#13;
During the talk we will focus on how python libraries are working in LINUX systems.&#13;
For interactions between python and the OS we will focus on libraries:&#13;
&#13;
-   os&#13;
-   sys&#13;
-   multiprocessing&#13;
&#13;
For interactions between python and the network we will focus on libraries:&#13;
&#13;
-   socket&#13;
-   ftplib&#13;
-   httplib / urllib / pycurl&#13;
&#13;
For data handling we will cover how to improve security of operations like:&#13;
&#13;
-   input/output sanitisation (files, strings, arguments)&#13;
-   writing to files or file descriptors&#13;
-   implicit and explicit object control using both "whitelist" and "blacklist" logics&#13;
-   exception handling by using meta-classes and decorators&#13;
&#13;
For each library we will proceed as follows:&#13;
&#13;
-   Review of library internal logic and data flow&#13;
-   Analysis of possible weaknesses in library code or logic&#13;
-   Introduction of a modified library logic able to cope with unexpected data&#13;
-   Description of modified functions to allow security checks and data validation &#13;
-   Examples of real problems and possible improvements to mitigate them&#13;
&#13;
We will explore how to make code able to react to improper imports, misuse of variables, insecure calls to functions by briefly covering some ways of using metaclasses, descriptors and decorators, method wrappers, traceback inspection and builtins. &#13;
&#13;
Then we will explore the use of metaclasses and class decorators to intercept reads/writes and internal operations, implement automatic type checking over object attributes and how to use iterators and generators to respond to maliciously formatted strings or data streams.&#13;
</description><speakers><speaker id="848"><name>Enrico Branca</name><profile>https://ep2014.europython.eu//en/accounts/profile/848/</profile><image></image></speaker></speakers></entry><entry id="10"><category>Talk</category><audience>Novice</audience><topics><topic>Gaming</topic></topics><start>1500</start><duration>30</duration><room id="1">C01</room><title>Brain Waves for Hackers</title><description>This talk will present how to use the "Neurosky Mindwave" headset with python software, and lay out the basic scientific and technical background.&#13;
&#13;
The Mindwave Mobile is a device that can be easily talked to using bluetooth, and it talks a binary protocol which is specifically designed to be useful without  much computing power in the receiving device or advanced knowledge of signal processing. In fact, an Arduino with a few lines of code is perfectly capable of parsing some of the byte stream and reacting to the mental state of the user, while fully-featured python software can do advanced analysis using PyEEG and Pandas.&#13;
&#13;
The same hardware module and protocol is used in the Nekomimi headset (mind-controlled cat ears for cosplay) and some Boardgames (MindFlex).&#13;
&#13;
A python library for interfacing with the headset is presented and will be demonstrated on stage. Mostly kivy applications will be used.&#13;
&#13;
Also I will present some data analysis you can perform with pandas and scipy.&#13;
&#13;
Neurofeedback is a type of mental exercise where a computer uses the EEG data to direct the user towards certain mental states. In the easiest configuration a program would display a bar with the "concentration" level, and the user would learn how to tilt this bar upwards. In more complicated setups a game could react favorably towards states like relaxation or concentration. Using Gamification, Neurofeedback can provide a more engaging experience for children or adults, than other techniques with similar goals, like mindfulness meditation, and the more immediate feedback should enhance the effectiveness of mental training, though that has not been investigated scientifically yet.&#13;
&#13;
Neurofeedback has been shown to be effective (albeit not recommended as sole treatment) in Patients with Attention Deficit Hyperactivity Disorder (ADHD), Epilepsy and Dementia. Some background about these conditions and applications of Neurofeedback to them will be given. The first use of Neurofeedback was done in Cats, during early experiments with EEG electrodes in the 60ies. Cats where conditioned to exhibit certain wave patterns, and later, due to a coincidence, the researchers noticed that the conditioned cats where more resistant to epilepsy-inducing medications. The effect has since been reproduced in humans, in cases where medications did not work sufficiently.&#13;
&#13;
Ample hints on not to treat any of this information as medical advice will be provided.&#13;
&#13;
The goal of this talk is to promote Neurofeedback as a useful mental training and to encourage development of applications around Neurofeedback and the analysis of EEG data, from the perspective of a python hacker.&#13;
&#13;
I gave a similar talk at PyConDe 2013 in Cologne. The new talk will be in English, show some improvements on the software, and more advanced demonstrations.</description><speakers><speaker id="225"><name>Andreas Klostermann</name><profile>https://ep2014.europython.eu//en/accounts/profile/225/</profile><image></image></speaker></speakers></entry><entry id="22"><category>Talk</category><audience>Novice</audience><topics><topic>Other</topic></topics><start>1500</start><duration>30</duration><room id="4">B09</room><title>Jython in practice</title><description>    A lot of people have heard of Jython, some have tried it, but it seems few have actually deployed it in a corporate environment. In this talk I'll share my experiences in using Jython as a testbed for Java applications, for rapid prototyping in Java desktop and web environments, and for embedding scripting capabilities in Java products.&#13;
&#13;
    Not everyone gets paid to work with Python all the time, but if you find yourself in a Java project, there are good chances you could benefit from Python without throwing out the Java stack. Using Jython, you can do rapid prototyping without the long edit-compile-test cycles normally associated with large Java projects, whether on the web or the desktop, and when testing an application might become a nightmare of scaffolding in Java, a little Jython may be just what you need to be able to run your tests smoothly.&#13;
&#13;
    At the end of this talk, I will put on my politician&#180;s hat and bring up the best - and worst - arguments to use to get permission to use Jython in a corporate environment. </description><speakers><speaker id="299"><name>Fredrik H&#229;&#229;rd</name><profile>https://ep2014.europython.eu//en/accounts/profile/299/</profile><image>https://ep2014.europython.eu//site_media/avatars/me_6.jpg</image></speaker></speakers></entry></day><day date="2014-07-23"><entry id="45"><category>Talk</category><audience>Advanced</audience><topics><topic>Science</topic></topics><start>0900</start><duration>60</duration><room id="2">B05/B06</room><title>Event discrete simulation with SimPy</title><description>Simulation is important for the analysis of complex systems or the analysis of&#13;
the impact of certain actions on that systems. They are especially useful if&#13;
the actions are potentially harmful or expensive.&#13;
&#13;
Simulation is used in various natural scientific and economic areas, e.g., for&#13;
the modeling and study of biological or physical systems, for resource&#13;
scheduling and optimization or at the research for the integration of renewable&#13;
energies into the power grid (my personal background). The simulated time can&#13;
thereby be seen as continuous or discrete (discrete time or discrete event).&#13;
&#13;
In this talk, I want to show why Python is a good choice for implementing&#13;
simulation models and how SimPy can help here.&#13;
&#13;
Structure of the talk (20min talking + 5min discussion + 5min buffer):&#13;
&#13;
- Why simulation? (5min)&#13;
- History of SimPy (3min)&#13;
- How does SimPy work? (9min)&#13;
- Conclusion (3min)&#13;
&#13;
In the introduction, I&#8217;ll briefly explain what simulation is and motivate, why&#13;
it is a useful tool.&#13;
&#13;
The main part will consist of an introduction and demonstration of SimPy. Since&#13;
SimPy is now more then ten years old, I&#8217;ll first give a quick overview about&#13;
its history and development. Afterwards, I&#8217;ll explain SimPy&#8217;s concepts and&#13;
features by means of simple examples.&#13;
&#13;
In the conclusion, I&#8217;ll give a short outlook on the future development of&#13;
SimPy.&#13;
&#13;
The main goal of this talk is to create awareness that simulation is a powerful&#13;
tool in a lot of domains and to give the audience enough information to ease&#13;
their first steps.</description><speakers><speaker id="368"><name>Stefan</name><profile>https://ep2014.europython.eu//en/accounts/profile/368/</profile><image>https://ep2014.europython.eu//site_media/avatars/ssc1.jpg</image></speaker></speakers></entry><entry id="59"><category>Talk</category><audience>Advanced</audience><topics><topic>Python Core</topic></topics><start>0900</start><duration>60</duration><room id="4">B09</room><title>Post-Mortem Debugging with Heap-Dumps</title><description>Post-Mortem Debugging with Heap-Dumps&#13;
=====================================&#13;
&#13;
UNIX core-dumps, Windows minidumps and analogous solutions of other operating systems are well established technologies for &#13;
post-mortem defect analysis of native-code processes. In principle those dumps can be used to analyse &#8222;interpreted&#8220; &#13;
programs running within a native-code interpreter-process. However in practise this approach is tedious and not always successful \[1\].&#13;
Therefore operating system independent dump methods were developed for some &#8222;interpreted&#8220; languages \[2\]. &#13;
A prominent example are Java heap dumps \[3\]. &#13;
&#13;
Unfortunately up to now there was no practically usable dump-method for Python. Various attempts were made &#13;
to utilise OS-level dump methods \[4, 5\]. In 2012 Eli Finer published the Python module *pydump* \[6\].&#13;
This module pickles the traceback of an exception and subsequently uses the pdb debugger to analyse the unpickled traceback.&#13;
Unfortunately *pydump* fails on PicklingErrors.&#13;
&#13;
In my talk I'll present the Python package [*pyheapdump*](https://pypi.python.org/pypi/pyheapdump). It has the same operation principle as Eli's *pydump*, but &#13;
is an independent implementation. *pyheapdump* uses an extended pickler &#13;
([sPickle](https://pypi.python.org/pypi/sPickle)) to serialise all relevant objects &#13;
of a Python process to a file. Later on a fault tolerant unpickler recreates the objects and a common Python&#13;
debugger can be used to analyse the dump. The pickler extensions make it possible to:&#13;
&#13;
 * pickle and unpickle many commonly not pickleable objects [7].&#13;
 * replace the remaining not pickleable objects by surrogate objects so that the resulting object graph is&#13;
   almost isomorphic to the original object graph.&#13;
   &#13;
Which objects are relevant? In its default operation mode *pyheapdump* &#13;
uses the frame-stacks of all threads as start point for pickling. Following the &#13;
usual rules for pickling the dump includes all local variables and all objects &#13;
reachable from a local variable and so on. That is usually enough for a successful defect analysis.&#13;
&#13;
Compared with other Python post-mortem debugging methods *pyheapdump* has several advantages:&#13;
&#13;
 * It is a pure Python solution and independent from the operation system.&#13;
 * Creation of the pyheapdump and fault analysis can be performed different computers.&#13;
 * It is not obstructive. It does not modify / monkey-patch or disturb the dumped &#13;
   process in any way, with the exception of loading additional modules.&#13;
 * If used with the Pydev-debugger, it supports multi-threaded applications.&#13;
 * If used with the Pydev-debugger and Stackless Python, it supports tasklets. &#13;
&#13;
The implementation of *pyheapdump* is fairly small, because it draws most of its functionality &#13;
from the underlying sPickle package and from the new Stackless-Support \[8\] of the&#13;
Pydev-Debugger. Therefore it is - despite of its short history - already a useful piece of software.&#13;
&#13;
Outline of the talk&#13;
-------------------&#13;
&#13;
1.	Introduction to the problem&#13;
2.	Previous works&#13;
3.	The concept of *pyheapdump*&#13;
4.	Live demonstration&#13;
5.	Open problems and further development&#13;
6.	Questions and Answers&#13;
&#13;
References&#13;
----------&#13;
&#13;
1. Andraz Tori, Python, 2011-01-16: *gdb and a very large core dump*, blog at &lt;http://www.zemanta.com/blog/python-gdb-large-core-dump/&gt;&#13;
2. David Pacheco, ACM Queue - Programming Languages Volume 9 Issue 10, October 2011: &#13;
   *Postmortem Debugging in Dynamic Environments*, &#13;
   PDF &lt;http://dl.acm.org/ft_gateway.cfm?id=2039361&amp;ftid=1050739&amp;dwn=1&amp;CFID=290171300&amp;CFTOKEN=95099236&gt;&#13;
3. Chris Bailey, Andrew Johnson, Kevin Grigorenko, IBM developerWorks, 2011-03-15: &#13;
   *Debugging from dumps - Diagnose more than memory leaks with Memory Analyzer*, &#13;
   PDF &lt;http://www.ibm.com/developerworks/library/j-memoryanalyzer/j-memoryanalyzer-pdf.pdf&gt;&#13;
4. Brian Curtin, 2011-09-29: *minidumper - Python crash dumps on Windows*, &#13;
   blog at &lt;http://blog.briancurtin.com/posts/20110929minidumper-python-crash-dumps-on-windows.html&gt;&#13;
5. David Malcolm, Fedora Feature, 2010-04-06: *Easier Python Debugging* &#13;
   at &lt;http://fedoraproject.org/wiki/Features/EasierPythonDebugging&gt;&#13;
6. Eli Finer, Github-Project, 2012: *pydump* at &lt;https://github.com/gooli/pydump&gt;&#13;
7. Anselm Kruis, EuroPython 2011: *Advanced Pickling with Stackless Python and sPickle*,&#13;
   archived talk at &lt;https://ep2013.europython.eu/conference/talks/advanced-pickling-with-stackless-python-and-spickle&gt;&#13;
8. Fabio Zadrozny, 2013-12-12: *PyDev 3.1.0 released*, &#13;
   blog at &lt;http://pydev.blogspot.de/2013/12/pydev-310-released.html&gt;&#13;
&#13;
</description><speakers><speaker id="252"><name>Anselm Kruis</name><profile>https://ep2014.europython.eu//en/accounts/profile/252/</profile><image>https://ep2014.europython.eu//site_media/avatars/kruis-gr.jpg</image></speaker></speakers></entry><entry id="77"><category>Talk</category><audience>Advanced</audience><topics><topic>Other</topic></topics><start>0900</start><duration>60</duration><room id="5">A08</room><title>Concurrent programming with Python and my little experiment</title><description>Concurrent programming in Python may be hard. A lot of solutions exists&#13;
though. Most of them are based on an eventloop. This talk will present&#13;
what I discovered and tested along the time with code examples, from&#13;
asyncore to asyncio, passing by gevent, eventlet, twisted and some new&#13;
alternatives like evergreen or gruvi. It will also present my little&#13;
experiment in porting the Go concurrency model in Python named [offset](http://github.com/benoitc/offset),&#13;
how it progressed in 1 year and how it became a fully usable library .&#13;
&#13;
This presentation will be an update of the presentation I gave at the FOSDEM 2014. It will introduce to the concurrency concepts and how they are implemented in the different libraries. &#13;
</description><speakers><speaker id="755"><name>Benoit Chesneau</name><profile>https://ep2014.europython.eu//en/accounts/profile/755/</profile><image>https://ep2014.europython.eu//site_media/avatars/13_-_1.jpg</image></speaker></speakers></entry><entry id="47"><category>Talk</category><audience>Advanced</audience><topics><topic>Other</topic></topics><start>0900</start><duration>60</duration><room id="1">C01</room><title>Compress Me, Stupid!</title><description>Compression is a technique to reduce the number of bits needed to&#13;
represent a given dataset. A very common use-case in the distributed&#13;
digital age is to reduce the size of files in order to reduce the time&#13;
and bandwidth requirements of sending a file from one location to&#13;
another.&#13;
&#13;
There are a large variety of different algorithms and implementations of&#13;
so called "codecs" - a term is derived from the fact that programs that&#13;
implement a compression algorithm commonly constitute of both a&#13;
compressor and a corresponding decompressor. There are many different&#13;
special purpose compressors that exploit specifics in the structure of the&#13;
input data, for example: MP3, Ogg and FLAC for audio data such as music,&#13;
GIF, JPEG and PNG for images and  MPEG for encoding video. Also, there&#13;
are many general purpose codecs that make no assumptions about the&#13;
structure of the data, for example: Zlib(DEFLATE), Bzip2(BWT) and LZMA.&#13;
&#13;
However, and due to the ever growing divide between memory access latency and CPU clock&#13;
speed a new use-case beyond faster file transfers and more efficient use&#13;
of disk-space has emerged: "in-memory compression".&#13;
&#13;
&#13;
Keeping data in RAM that is compressed also means that the CPU has to&#13;
do more work in order to make use of it.  However, if the compressor&#13;
is fast enough, this decompression overhead could pay off, and&#13;
applications could work with compressed data transparently, and so not&#13;
even noticing the slowdown due to the extra effort for&#13;
compression/decompression.&#13;
&#13;
This technique can be very beneficial in a variety of scenarios where&#13;
RAM availability is critical.  For example, in-memory caching systems&#13;
like Memcached or Redis could store more data using the same resources&#13;
thereby optimizing resource usage.  Another use case is to use&#13;
compression for in-memory data containers, &#224; la NumPy's ndarray or&#13;
Pandas' DataFrame, allowing for improved memory usage and potentially&#13;
allow for accelerated computations.&#13;
&#13;
In our talk, we will explain first why we are in a moment of computer&#13;
history that [in-memory compression can be beneficial for modern&#13;
applications] [1].&#13;
&#13;
Then, we will introduce [Blosc] [2], a high speed&#13;
meta-compressor, allowing other existing compressors (BloscLZ, LZ4,&#13;
Snappy or even Zlib) to leverage the SIMD and multithreading framework&#13;
that it provides and help achieving extremely fast operation&#13;
(frequently faster than a plain memcpy() system call).&#13;
&#13;
Finally, we will show some existing data handling libraries ([Bloscpack] [3], [PyTables] [4], [BLZ] [5]) -- all written in Python -- that&#13;
already use Blosc today for fulfilling the promise of faster operations by&#13;
doing in-memory compressing.&#13;
&#13;
[1]: http://www.pytables.org/docs/CISE-12-2-ScientificPro.pdf&#13;
[2]: http://www.blosc.org&#13;
[3]: https://github.com/Blosc/bloscpack&#13;
[4]: http://www.pytables.org&#13;
[5]: http://continuum.io/blog/blz-format</description><speakers><speaker id="695"><name>Francesc Alted</name><profile>https://ep2014.europython.eu//en/accounts/profile/695/</profile><image>https://ep2014.europython.eu//site_media/avatars/foto-meua.png</image></speaker></speakers></entry><entry id="26"><category>Talk</category><audience>Novice</audience><topics><topic>Science</topic></topics><start>0900</start><duration>60</duration><room id="3">B07/B08</room><title>Learning Chess from data</title><description>Can empirical samples unveil the big picture?&#13;
Is chess games descriptions expose good enough data to gain understanding of chess rules - legal piece moves, castling, check versus checkmate, etc.&#13;
Which features are important in describing a chess game and which features are not. What is a good representation of a chess game for this uses.&#13;
What is the minimal sample size which is required in order to learn this in a good enough manner and where this learning can go wrong.&#13;
&#13;
&#13;
**Ne3  =&gt;  E=mc2**&#13;
&#13;
Looking at the bigger picture - Can we understand big systems based on empirical samples.&#13;
Can we reverse engineer physics and discover how physical system work based on no external knowledge beside empirical samples.</description><speakers><speaker id="302"><name>Niv</name><profile>https://ep2014.europython.eu//en/accounts/profile/302/</profile><image>https://ep2014.europython.eu//site_media/avatars/561952_102971469866829_419869712_n.jpg</image></speaker><speaker id="304"><name>tomr</name><profile>https://ep2014.europython.eu//en/accounts/profile/304/</profile><image></image></speaker></speakers></entry><entry id="61"><category>Talk</category><audience>Advanced</audience><topics><topic>Science</topic></topics><start>1000</start><duration>30</duration><room id="4">B09</room><title>Scikit-learn to "learn them all"</title><description>**Machine Learning** is about *using the right features, to build the right &#13;
models, to achieve the right tasks* [[Flach, 2012]][0]&#13;
However, to come up with a definition of what actually means **right** for &#13;
the problem at the hand, it is required to analyse &#13;
huge amounts of data, and to evaluate the performance of different algorithms &#13;
on these data.&#13;
&#13;
However, deriving a working machine learning solution for a given problem &#13;
is far from being a *waterfall* process. &#13;
It is an iterative process where continuous refinements are required for the &#13;
data to be used (i.e., the *right features*), and the algorithms to apply &#13;
(i.e., the *right models*).&#13;
&#13;
In this scenario, Python has been found very useful for practitioners and &#13;
researchers: its high-level nature, in combination with available tools and &#13;
libraries, allows to rapidly implement working machine learning code &#13;
without *reinventing the wheel*.&#13;
&#13;
[**Scikit-learn**](http://scikit-learn.org/stable/) is an actively &#13;
developing Python library, built on top of the solid `numpy` and `scipy` &#13;
packages.&#13;
&#13;
Scikit-learn (`sklearn`) is an *all-in-one* software solution, providing &#13;
implementations for several machine learning methods, along with datasets and &#13;
(performance) evaluation algorithms.&#13;
&#13;
These "batteries" included in the library, in combination with a nice and intuitive&#13;
software API, have made scikit-learn to become one of the most popular Python &#13;
package to write machine learning code.&#13;
&#13;
In this talk, a general overview of scikit-learn will be presented, along with &#13;
brief explanations of the techniques provided out-of-the-box by the library.&#13;
&#13;
These explanations will be supported by working code examples, and insights on &#13;
algorithms' implementations aimed at providing hints on &#13;
how to extend the library code.&#13;
&#13;
Moreover, advantages and limitations of the `sklearn` package will be discussed &#13;
according to other existing machine learning Python libraries&#13;
(e.g., [`shogun`](http://shogun-toolbox.org "Shogun Toolbox"), &#13;
[`pyML`](http://pyml.sourceforge.net "PyML"), &#13;
[`mlpy`](http://mlpy.sourceforge.net "MLPy")).&#13;
&#13;
In conclusion, (examples of) applications of scikit-learn to big data and &#13;
computational intensive tasks will be also presented.&#13;
&#13;
The general outline of the talk is reported as follows (the order of the topics may vary):&#13;
&#13;
*   Intro to Machine Learning&#13;
    *   Machine Learning in Python&#13;
    *   Intro to Scikit-Learn&#13;
*   Overview of Scikit-Learn&#13;
    *   Comparison with other existing ML Python libraries&#13;
*   Supervised Learning with `sklearn`&#13;
    *   Text Classification with SVM and Kernel Methods&#13;
*   Unsupervised Learning with `sklearn`&#13;
    *   Partitional and Model-based Clustering (i.e., k-means and Mixture Models)&#13;
*   Scaling up Machine Learning&#13;
    *   Parallel and Large Scale ML with `sklearn`&#13;
&#13;
The talk is intended for an intermediate level audience (i.e., Advanced).&#13;
It requires basic math skills and a good knowledge of the Python language.&#13;
&#13;
Good knowledge of the `numpy` and `scipy` packages is also a plus.&#13;
&#13;
[0]: http://goo.gl/BnhoHa "Machine Learning: The Art and Science of Algorithms that Make Sense of Data, *Peter Flach, 2012*"</description><speakers><speaker id="250"><name>Valerio Maggio</name><profile>https://ep2014.europython.eu//en/accounts/profile/250/</profile><image>https://ep2014.europython.eu//site_media/avatars/me_kyoto_3.jpg</image></speaker></speakers></entry><entry id="36"><category>Talk</category><audience>Advanced</audience><topics><topic>Science</topic></topics><start>1000</start><duration>30</duration><room id="1">C01</room><title>Extending Scikit-Learn with your own Regressor</title><description>Scikit-Learn (http://scikit-learn.org/) is a well-known and popular framework for machine learning that is used by Data Scientists all over the world. We show in a practical way how you can add your own estimator following the interfaces of Scikit-Learn. First we give a small introduction to the design of Scikit-Learn and its inner workings. Then we show how easily Scikit-Learn can be extended by creating an own estimator. In order to demonstrate this, we extend Scikit-Learn by the popular and robust Theil-Sen Estimator (http://en.wikipedia.org/wiki/Theil%E2%80%93Sen_estimator) that is currently not in Scikit-Learn. We also motivate this estimator by outlining some of its superior properties compared to the ordinary least squares method (LinearRegression in Scikit-Learn).</description><speakers><speaker id="375"><name>Florian Wilhelm</name><profile>https://ep2014.europython.eu//en/accounts/profile/375/</profile><image></image></speaker><speaker id="430"><name>Felix Wick</name><profile>https://ep2014.europython.eu//en/accounts/profile/430/</profile><image>https://ep2014.europython.eu//site_media/avatars/felix1.jpg</image></speaker></speakers></entry><entry id="73"><category>Talk</category><audience>Novice</audience><topics><topic>Other</topic></topics><start>1000</start><duration>30</duration><room id="3">B07/B08</room><title>Graph Databases, a little connected tour</title><description>There are many kinds of NoSQL databases like, document databases, key-value, column databases and graph databases.&#13;
In some scenarios is more convenient to store our data as a graph, because we want to extract and study information relative to these connections. In this scenario, graph databases are the ideal, they are designed and implemented to deal with connected information in a efficient way.&#13;
In this talk I'll explain why NoSQL is necessary in some contexts as an alternative to traditional relational databases. How graph databases allow developers model their domains in a natural way without translating these domain models to an relational model with some artificial data like foreign keys and why is more efficient a graph database than a relational one or even a document database in a high connected environment. Then I'll explain specific characteristics of Neo4J as well as how to use Cypher the neo4j query language through python.</description><speakers><speaker id="175"><name>Francisco Fern&#225;ndez Casta&#241;o</name><profile>https://ep2014.europython.eu//en/accounts/profile/175/</profile><image>https://ep2014.europython.eu//site_media/avatars/foto.jpeg</image></speaker></speakers></entry><entry id="24"><category>Talk</category><audience>Novice</audience><topics><topic>Python Core</topic></topics><start>1000</start><duration>30</duration><room id="2">B05/B06</room><title>Python Debugger Uncovered</title><description>Presentation describes how to implement debugger for Python and has 4 parts:&#13;
&#13;
* Tracing Python code&#13;
&#13;
    Explains how to use trace function&#13;
&#13;
* Debugger Architecture&#13;
&#13;
    Explains which parts consists of a modern full-fledged debugger.&#13;
&#13;
* A Bit of Details&#13;
&#13;
    Explains how to make code to work for all python versions and implementations, survive gevent monkey-patching etc.&#13;
&#13;
* Cool Features&#13;
&#13;
    Explains how to implement exception handling and multiprocess debugging&#13;
</description><speakers><speaker id="358"><name>Dmitry Trofimov</name><profile>https://ep2014.europython.eu//en/accounts/profile/358/</profile><image>https://ep2014.europython.eu//site_media/avatars/DSC_4262-smaller.jpg</image></speaker></speakers></entry><entry id="17"><category>Talk</category><audience>Novice</audience><topics><topic>Education</topic></topics><start>1000</start><duration>30</duration><room id="5">A08</room><title>VPython goes to School</title><description>My presentation is focused mainly on my teaching experience in a high school using VPython. I've posed some problems to my students to solve with VPython: from basic static building representations like castle to more complex dynamic models like bouncing balls.&#13;
This approach seems a good way to get in touch with computer programming concepts and to link computer science with other disciplines like Math, Geometry, Physics, Chemistry</description><speakers><speaker id="259"><name>Mauri</name><profile>https://ep2014.europython.eu//en/accounts/profile/259/</profile><image>https://ep2014.europython.eu//site_media/avatars/mauri_in_madeira_2013.jpg</image></speaker></speakers></entry><entry id="28"><category>Training</category><audience>Advanced</audience><topics></topics><start>1000</start><duration>180</duration><room id="6">A03/A04</room><title>RESTful services with pyramid and cornice</title><description>The combination of python, pyramid and cornice gives you a very powerful and elegant means to write concise, well tested and well documented RESTful services.&#13;
&#13;
This training will get you up and running with a scaffold of best practices in no time!</description><speakers><speaker id="387"><name>tomster</name><profile>https://ep2014.europython.eu//en/accounts/profile/387/</profile><image></image></speaker></speakers></entry><entry id="79"><category>Training</category><audience>Advanced</audience><topics></topics><start>1000</start><duration>180</duration><room id="7">A05/A06</room><title>Making your first contribution to OpenStack</title><description>Taking people from a DevStack install to a first contribution.&#13;
&#13;
Objectives&#13;
----------&#13;
By the end of the session, participants will:&#13;
&#13;
 * have all the necessary accounts and tools set up for contributing&#13;
 * know how to submit a contribution to an OpenStack project&#13;
 * understand the OpenStack contribution process&#13;
 * have a first contribution completed or underway, and know what are the next steps&#13;
&#13;
The process for making both code and documentation contributions is the same in OpenStack. For this session, participants will be encouraged to choose a task of either type.&#13;
&#13;
Pre-requisites:&#13;
---------------&#13;
Participants should have:&#13;
&#13;
 * A basic knowledge of git (cloning a repository, committing)&#13;
 * A SSH key pair (instructions on how to create one can be found online, for instance [https://unfuddle.com/support/docs/topics/ssh_keypair](https://unfuddle.com/support/docs/topics/ssh_keypair))&#13;
 * A Virtual Machine (VM) with DevStack installed (see below for details)&#13;
 * Be comfortable with Python&#13;
&#13;
Contributing to OpenStack requires signing a Contributor Licence Agreement (CLA). If your employment contract has a restrictive IP clause, you may want to check first with your company lawyers whether you can sign it. See [https://review.openstack.org/static/cla.html](https://review.openstack.org/static/cla.html) for the text of the licence.</description><speakers><speaker id="377"><name>Julie</name><profile>https://ep2014.europython.eu//en/accounts/profile/377/</profile><image></image></speaker></speakers></entry><entry id="3"><category></category><audience></audience><topics></topics><start>1030</start><duration>30</duration><room>C01, B05/B06, B07/B08, B09, A08</room><title>&#127861; Breakfast</title><description></description><speakers></speakers></entry><entry id="64"><category>Talk</category><audience>Novice</audience><topics><topic>Web</topic></topics><start>1100</start><duration>45</duration><room id="1">C01</room><title>Building Realtime Web Applications with WebRTC and Python</title><description>Introduction&#13;
===========&#13;
This talk will first introduce the audience to WebRTC and then discuss about how to implement the server side logic of a WebRTC app using Python. &#13;
&#13;
WebRTC is a free, open project that enables web browsers with plugin-less Real-Time Communications (RTC) capabilities via simple JavaScript APIs. What makes WebRTC special is that the data travels from one client to another without going through the server. &#13;
&#13;
The main functions of WebRTC can be broadly categorized into three types. &#13;
&#13;
- Access and acquire video and audio streams&#13;
- Establish a connection between peers and stream audio/video.&#13;
- Communicate arbitrary data.&#13;
&#13;
WebRTC uses three different JavaScript APIs to perform these three functions. These APIs are:&#13;
&#13;
- MediaStream (aka getUserMedia)&#13;
- RTCPeerConnection&#13;
- RTCDataChannel&#13;
&#13;
MediaStream API performs the task of accessing the webcam and/or microphone of the device and acquire the video and/or audio stream from them. RTCPeerConnection API establishes connection between peers and streams audio and video data. This API also does all the encoding and decoding of audio/video data. The third API, RTCDataChannel helps to communicate arbitrary data from one client to the other.&#13;
&#13;
There will be short demos to demonstrate the functionalities of these APIs.&#13;
&#13;
Signaling and Session Control&#13;
========================&#13;
&#13;
WebRTC uses RTCPeerConnection to communicate streaming data between browsers, but some sort of mechanism is needed to coordinate this communication and to send control messages. This process is known as signaling.&#13;
&#13;
Signaling is used to exchange three types of information.&#13;
&#13;
- Session control messages: to initialize or close communication and report errors.&#13;
- Network configuration: to the outside world, what's my computer's IP address and port?&#13;
- Media capabilities: what codecs and resolutions can be handled by my browser and the browser it wants to communicate with?&#13;
&#13;
This can be implemented using any appropriate two way communication channel.&#13;
&#13;
Implementing signaling in Python&#13;
==========================&#13;
&#13;
Next, we will have a look at how to implement this signaling mechanism in Python. ( Demonstration with annotated code and live application.)&#13;
&#13;
### Google AppEngine and the Channel API ###&#13;
Google AppEngine has a channel API which offers persistent connections between your application and Google servers, allowing your application to send messages to JavaScript clients in real time without the use of polling. We'll use this Channel API to build the signaling system of our WebRTC app on top of webapp2 and flask framework. &#13;
&#13;
### Flask and gevent ###&#13;
We'll implement the same signaling system again, this time on top of Flask using gevent for the persistent connection between the browser and our application. &#13;
&#13;
Outline of the talk&#13;
===============&#13;
### Intro (5 min) ###&#13;
- Who are we?&#13;
- What is WebRTC?&#13;
- Functions of WebRTC.&#13;
&#13;
### WebRTC APIs and Demos (3 min) ###&#13;
- MediaStream (getUserMedia) API&#13;
- RTCPeerConnection API&#13;
- RTCDataChannel API&#13;
&#13;
### Signaling in WebRTC Applications (3 min) ###&#13;
- What is signaling?&#13;
- Why is it needed?&#13;
- How to implement it?&#13;
&#13;
### Implementation of signaling (16 min) ###&#13;
- Implementation using Google AppEngine and Channel API&#13;
- Implementation using Flask and gevent&#13;
&#13;
### Questions (3 min) ###&#13;
</description><speakers><speaker id="31"><name>Tarashish Mishra</name><profile>https://ep2014.europython.eu//en/accounts/profile/31/</profile><image>https://ep2014.europython.eu//site_media/avatars/pic.jpg</image></speaker><speaker id="400"><name>Rishabh Raj</name><profile>https://ep2014.europython.eu//en/accounts/profile/400/</profile><image>https://ep2014.europython.eu//site_media/avatars/propic.jpg</image></speaker></speakers></entry><entry id="91"><category>Talk</category><audience>Advanced</audience><topics><topic>Python Core</topic></topics><start>1100</start><duration>45</duration><room id="2">B05/B06</room><title>Fun with cPython memory allocator</title><description>Working with Python does not usually involve debugging memory problems: the interpreter takes care of allocating and releasing system memory and you get to enjoy working on real problems. But what if you encounter such problems? What if your program never releases memory? How do you debug it?&#13;
&#13;
I will tell a story of one programmer discovering such problems. The talk will take listeners on a journey of issues they can encounter, tools they can use to debug the problems and possible solutions to seek out. There will also be a brief mention of general memory management principles.&#13;
&#13;
cPython uses a combination of its own allocator, `malloc`, and `mmap` pools to manage memory of Python programs. It usually is smart enough, but there are some darker corners that are not well known by an average Joe Programmer (read: me). &#13;
&#13;
There are tools that can help debug memory problems, but those are also relatively unknown, and tend to have documentation that one might find lacking. I will describe one such tool, called `guppy`, which I have found particulary helpful.</description><speakers><speaker id="471"><name>oinopion</name><profile>https://ep2014.europython.eu//en/accounts/profile/471/</profile><image></image></speaker></speakers></entry><entry id="6"><category></category><audience></audience><topics></topics><start>1230</start><duration>90</duration><room>C01, B05/B06, B07/B08, B09, A08</room><title>&#127860; Lunch</title><description></description><speakers></speakers></entry></day></schedule>
